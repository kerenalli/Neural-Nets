{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20210203_AutoEncoderforClassification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPwsdsVP0riMkIf1JCQRC5o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kerenalli/Neural-Nets/blob/main/20210203_AutoEncoderforClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ELgoa3G9M0xu",
        "outputId": "2864605c-6969-4b1c-a24d-0308c9ab2ad9"
      },
      "source": [
        "# train autoencoder for classification with no compression in the bottleneck layer\r\n",
        "from sklearn.datasets import make_classification\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import Input\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.layers import LeakyReLU\r\n",
        "from tensorflow.keras.layers import BatchNormalization\r\n",
        "from tensorflow.keras.utils import plot_model\r\n",
        "from matplotlib import pyplot\r\n",
        "# define dataset\r\n",
        "X, y = make_classification(n_samples=1000, n_features=100, n_informative=10, n_redundant=90, random_state=1)\r\n",
        "# number of input columns\r\n",
        "n_inputs = X.shape[1]\r\n",
        "# split into train test sets\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\r\n",
        "# scale data\r\n",
        "t = MinMaxScaler()\r\n",
        "t.fit(X_train)\r\n",
        "X_train = t.transform(X_train)\r\n",
        "X_test = t.transform(X_test)\r\n",
        "# define encoder\r\n",
        "visible = Input(shape=(n_inputs,))\r\n",
        "# encoder level 1\r\n",
        "e = Dense(n_inputs*3)(visible)\r\n",
        "e = BatchNormalization()(e)\r\n",
        "e = LeakyReLU()(e)\r\n",
        "# encoder level 2\r\n",
        "e = Dense(n_inputs)(e)\r\n",
        "e = BatchNormalization()(e)\r\n",
        "e = LeakyReLU()(e)\r\n",
        "# bottleneck\r\n",
        "n_bottleneck = n_inputs\r\n",
        "bottleneck = Dense(n_bottleneck)(e)\r\n",
        "# define decoder, level 1\r\n",
        "d = Dense(n_inputs)(bottleneck)\r\n",
        "d = BatchNormalization()(d)\r\n",
        "d = LeakyReLU()(d)\r\n",
        "# decoder level 2\r\n",
        "d = Dense(n_inputs*3)(d)\r\n",
        "d = BatchNormalization()(d)\r\n",
        "d = LeakyReLU()(d)\r\n",
        "# output layer\r\n",
        "output = Dense(n_inputs, activation='linear')(d)\r\n",
        "# define autoencoder model\r\n",
        "model = Model(inputs=visible, outputs=output)\r\n",
        "# compile autoencoder model\r\n",
        "model.compile(optimizer='adam', loss='mse')\r\n",
        "# plot the autoencoder\r\n",
        "plot_model(model, 'autoencoder_no_compress.png', show_shapes=True)\r\n",
        "# fit the autoencoder model to reconstruct input\r\n",
        "history = model.fit(X_train, X_train, epochs=200, batch_size=16, verbose=2, validation_data=(X_test,X_test))\r\n",
        "# plot loss\r\n",
        "pyplot.plot(history.history['loss'], label='train')\r\n",
        "pyplot.plot(history.history['val_loss'], label='test')\r\n",
        "pyplot.legend()\r\n",
        "pyplot.show()\r\n",
        "# define an encoder model (without the decoder)\r\n",
        "encoder = Model(inputs=visible, outputs=bottleneck)\r\n",
        "plot_model(encoder, 'encoder_no_compress.png', show_shapes=True)\r\n",
        "# save the encoder to file\r\n",
        "encoder.save('encoder.h5')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "42/42 - 2s - loss: 0.2048 - val_loss: 0.1898\n",
            "Epoch 2/200\n",
            "42/42 - 0s - loss: 0.0358 - val_loss: 0.1052\n",
            "Epoch 3/200\n",
            "42/42 - 0s - loss: 0.0241 - val_loss: 0.0563\n",
            "Epoch 4/200\n",
            "42/42 - 0s - loss: 0.0187 - val_loss: 0.0306\n",
            "Epoch 5/200\n",
            "42/42 - 0s - loss: 0.0169 - val_loss: 0.0195\n",
            "Epoch 6/200\n",
            "42/42 - 0s - loss: 0.0145 - val_loss: 0.0134\n",
            "Epoch 7/200\n",
            "42/42 - 0s - loss: 0.0135 - val_loss: 0.0107\n",
            "Epoch 8/200\n",
            "42/42 - 0s - loss: 0.0129 - val_loss: 0.0089\n",
            "Epoch 9/200\n",
            "42/42 - 0s - loss: 0.0113 - val_loss: 0.0076\n",
            "Epoch 10/200\n",
            "42/42 - 0s - loss: 0.0110 - val_loss: 0.0070\n",
            "Epoch 11/200\n",
            "42/42 - 0s - loss: 0.0112 - val_loss: 0.0071\n",
            "Epoch 12/200\n",
            "42/42 - 0s - loss: 0.0111 - val_loss: 0.0071\n",
            "Epoch 13/200\n",
            "42/42 - 0s - loss: 0.0099 - val_loss: 0.0060\n",
            "Epoch 14/200\n",
            "42/42 - 0s - loss: 0.0098 - val_loss: 0.0056\n",
            "Epoch 15/200\n",
            "42/42 - 0s - loss: 0.0095 - val_loss: 0.0067\n",
            "Epoch 16/200\n",
            "42/42 - 0s - loss: 0.0088 - val_loss: 0.0059\n",
            "Epoch 17/200\n",
            "42/42 - 0s - loss: 0.0085 - val_loss: 0.0063\n",
            "Epoch 18/200\n",
            "42/42 - 0s - loss: 0.0088 - val_loss: 0.0057\n",
            "Epoch 19/200\n",
            "42/42 - 0s - loss: 0.0086 - val_loss: 0.0065\n",
            "Epoch 20/200\n",
            "42/42 - 0s - loss: 0.0083 - val_loss: 0.0059\n",
            "Epoch 21/200\n",
            "42/42 - 0s - loss: 0.0076 - val_loss: 0.0046\n",
            "Epoch 22/200\n",
            "42/42 - 0s - loss: 0.0071 - val_loss: 0.0057\n",
            "Epoch 23/200\n",
            "42/42 - 0s - loss: 0.0077 - val_loss: 0.0049\n",
            "Epoch 24/200\n",
            "42/42 - 0s - loss: 0.0082 - val_loss: 0.0049\n",
            "Epoch 25/200\n",
            "42/42 - 0s - loss: 0.0078 - val_loss: 0.0057\n",
            "Epoch 26/200\n",
            "42/42 - 0s - loss: 0.0075 - val_loss: 0.0047\n",
            "Epoch 27/200\n",
            "42/42 - 0s - loss: 0.0069 - val_loss: 0.0045\n",
            "Epoch 28/200\n",
            "42/42 - 0s - loss: 0.0069 - val_loss: 0.0047\n",
            "Epoch 29/200\n",
            "42/42 - 0s - loss: 0.0074 - val_loss: 0.0051\n",
            "Epoch 30/200\n",
            "42/42 - 0s - loss: 0.0067 - val_loss: 0.0036\n",
            "Epoch 31/200\n",
            "42/42 - 0s - loss: 0.0065 - val_loss: 0.0041\n",
            "Epoch 32/200\n",
            "42/42 - 0s - loss: 0.0064 - val_loss: 0.0040\n",
            "Epoch 33/200\n",
            "42/42 - 0s - loss: 0.0065 - val_loss: 0.0045\n",
            "Epoch 34/200\n",
            "42/42 - 0s - loss: 0.0068 - val_loss: 0.0037\n",
            "Epoch 35/200\n",
            "42/42 - 0s - loss: 0.0068 - val_loss: 0.0040\n",
            "Epoch 36/200\n",
            "42/42 - 0s - loss: 0.0066 - val_loss: 0.0049\n",
            "Epoch 37/200\n",
            "42/42 - 0s - loss: 0.0066 - val_loss: 0.0040\n",
            "Epoch 38/200\n",
            "42/42 - 0s - loss: 0.0063 - val_loss: 0.0040\n",
            "Epoch 39/200\n",
            "42/42 - 0s - loss: 0.0060 - val_loss: 0.0035\n",
            "Epoch 40/200\n",
            "42/42 - 0s - loss: 0.0065 - val_loss: 0.0043\n",
            "Epoch 41/200\n",
            "42/42 - 0s - loss: 0.0061 - val_loss: 0.0035\n",
            "Epoch 42/200\n",
            "42/42 - 0s - loss: 0.0055 - val_loss: 0.0033\n",
            "Epoch 43/200\n",
            "42/42 - 0s - loss: 0.0064 - val_loss: 0.0035\n",
            "Epoch 44/200\n",
            "42/42 - 0s - loss: 0.0056 - val_loss: 0.0029\n",
            "Epoch 45/200\n",
            "42/42 - 0s - loss: 0.0057 - val_loss: 0.0037\n",
            "Epoch 46/200\n",
            "42/42 - 0s - loss: 0.0061 - val_loss: 0.0031\n",
            "Epoch 47/200\n",
            "42/42 - 0s - loss: 0.0054 - val_loss: 0.0034\n",
            "Epoch 48/200\n",
            "42/42 - 0s - loss: 0.0056 - val_loss: 0.0037\n",
            "Epoch 49/200\n",
            "42/42 - 0s - loss: 0.0055 - val_loss: 0.0026\n",
            "Epoch 50/200\n",
            "42/42 - 0s - loss: 0.0054 - val_loss: 0.0049\n",
            "Epoch 51/200\n",
            "42/42 - 0s - loss: 0.0060 - val_loss: 0.0036\n",
            "Epoch 52/200\n",
            "42/42 - 0s - loss: 0.0054 - val_loss: 0.0036\n",
            "Epoch 53/200\n",
            "42/42 - 0s - loss: 0.0056 - val_loss: 0.0037\n",
            "Epoch 54/200\n",
            "42/42 - 0s - loss: 0.0057 - val_loss: 0.0034\n",
            "Epoch 55/200\n",
            "42/42 - 0s - loss: 0.0054 - val_loss: 0.0034\n",
            "Epoch 56/200\n",
            "42/42 - 0s - loss: 0.0056 - val_loss: 0.0035\n",
            "Epoch 57/200\n",
            "42/42 - 0s - loss: 0.0058 - val_loss: 0.0033\n",
            "Epoch 58/200\n",
            "42/42 - 0s - loss: 0.0058 - val_loss: 0.0038\n",
            "Epoch 59/200\n",
            "42/42 - 0s - loss: 0.0056 - val_loss: 0.0045\n",
            "Epoch 60/200\n",
            "42/42 - 0s - loss: 0.0056 - val_loss: 0.0034\n",
            "Epoch 61/200\n",
            "42/42 - 0s - loss: 0.0056 - val_loss: 0.0041\n",
            "Epoch 62/200\n",
            "42/42 - 0s - loss: 0.0050 - val_loss: 0.0034\n",
            "Epoch 63/200\n",
            "42/42 - 0s - loss: 0.0052 - val_loss: 0.0029\n",
            "Epoch 64/200\n",
            "42/42 - 0s - loss: 0.0053 - val_loss: 0.0028\n",
            "Epoch 65/200\n",
            "42/42 - 0s - loss: 0.0054 - val_loss: 0.0030\n",
            "Epoch 66/200\n",
            "42/42 - 0s - loss: 0.0052 - val_loss: 0.0026\n",
            "Epoch 67/200\n",
            "42/42 - 0s - loss: 0.0052 - val_loss: 0.0033\n",
            "Epoch 68/200\n",
            "42/42 - 0s - loss: 0.0052 - val_loss: 0.0026\n",
            "Epoch 69/200\n",
            "42/42 - 0s - loss: 0.0054 - val_loss: 0.0031\n",
            "Epoch 70/200\n",
            "42/42 - 0s - loss: 0.0051 - val_loss: 0.0030\n",
            "Epoch 71/200\n",
            "42/42 - 0s - loss: 0.0049 - val_loss: 0.0033\n",
            "Epoch 72/200\n",
            "42/42 - 0s - loss: 0.0049 - val_loss: 0.0028\n",
            "Epoch 73/200\n",
            "42/42 - 0s - loss: 0.0052 - val_loss: 0.0031\n",
            "Epoch 74/200\n",
            "42/42 - 0s - loss: 0.0047 - val_loss: 0.0029\n",
            "Epoch 75/200\n",
            "42/42 - 0s - loss: 0.0046 - val_loss: 0.0033\n",
            "Epoch 76/200\n",
            "42/42 - 0s - loss: 0.0048 - val_loss: 0.0029\n",
            "Epoch 77/200\n",
            "42/42 - 0s - loss: 0.0052 - val_loss: 0.0028\n",
            "Epoch 78/200\n",
            "42/42 - 0s - loss: 0.0050 - val_loss: 0.0027\n",
            "Epoch 79/200\n",
            "42/42 - 0s - loss: 0.0043 - val_loss: 0.0022\n",
            "Epoch 80/200\n",
            "42/42 - 0s - loss: 0.0044 - val_loss: 0.0023\n",
            "Epoch 81/200\n",
            "42/42 - 0s - loss: 0.0047 - val_loss: 0.0027\n",
            "Epoch 82/200\n",
            "42/42 - 0s - loss: 0.0048 - val_loss: 0.0034\n",
            "Epoch 83/200\n",
            "42/42 - 0s - loss: 0.0048 - val_loss: 0.0028\n",
            "Epoch 84/200\n",
            "42/42 - 0s - loss: 0.0046 - val_loss: 0.0023\n",
            "Epoch 85/200\n",
            "42/42 - 0s - loss: 0.0048 - val_loss: 0.0036\n",
            "Epoch 86/200\n",
            "42/42 - 0s - loss: 0.0051 - val_loss: 0.0027\n",
            "Epoch 87/200\n",
            "42/42 - 0s - loss: 0.0048 - val_loss: 0.0031\n",
            "Epoch 88/200\n",
            "42/42 - 0s - loss: 0.0047 - val_loss: 0.0026\n",
            "Epoch 89/200\n",
            "42/42 - 0s - loss: 0.0040 - val_loss: 0.0021\n",
            "Epoch 90/200\n",
            "42/42 - 0s - loss: 0.0045 - val_loss: 0.0027\n",
            "Epoch 91/200\n",
            "42/42 - 0s - loss: 0.0044 - val_loss: 0.0027\n",
            "Epoch 92/200\n",
            "42/42 - 0s - loss: 0.0044 - val_loss: 0.0024\n",
            "Epoch 93/200\n",
            "42/42 - 0s - loss: 0.0047 - val_loss: 0.0022\n",
            "Epoch 94/200\n",
            "42/42 - 0s - loss: 0.0042 - val_loss: 0.0031\n",
            "Epoch 95/200\n",
            "42/42 - 0s - loss: 0.0043 - val_loss: 0.0020\n",
            "Epoch 96/200\n",
            "42/42 - 0s - loss: 0.0043 - val_loss: 0.0021\n",
            "Epoch 97/200\n",
            "42/42 - 0s - loss: 0.0047 - val_loss: 0.0034\n",
            "Epoch 98/200\n",
            "42/42 - 0s - loss: 0.0048 - val_loss: 0.0039\n",
            "Epoch 99/200\n",
            "42/42 - 0s - loss: 0.0044 - val_loss: 0.0028\n",
            "Epoch 100/200\n",
            "42/42 - 0s - loss: 0.0043 - val_loss: 0.0024\n",
            "Epoch 101/200\n",
            "42/42 - 0s - loss: 0.0043 - val_loss: 0.0026\n",
            "Epoch 102/200\n",
            "42/42 - 0s - loss: 0.0042 - val_loss: 0.0022\n",
            "Epoch 103/200\n",
            "42/42 - 0s - loss: 0.0045 - val_loss: 0.0026\n",
            "Epoch 104/200\n",
            "42/42 - 0s - loss: 0.0041 - val_loss: 0.0019\n",
            "Epoch 105/200\n",
            "42/42 - 0s - loss: 0.0043 - val_loss: 0.0038\n",
            "Epoch 106/200\n",
            "42/42 - 0s - loss: 0.0048 - val_loss: 0.0034\n",
            "Epoch 107/200\n",
            "42/42 - 0s - loss: 0.0042 - val_loss: 0.0027\n",
            "Epoch 108/200\n",
            "42/42 - 0s - loss: 0.0041 - val_loss: 0.0018\n",
            "Epoch 109/200\n",
            "42/42 - 0s - loss: 0.0040 - val_loss: 0.0016\n",
            "Epoch 110/200\n",
            "42/42 - 0s - loss: 0.0042 - val_loss: 0.0027\n",
            "Epoch 111/200\n",
            "42/42 - 0s - loss: 0.0042 - val_loss: 0.0019\n",
            "Epoch 112/200\n",
            "42/42 - 0s - loss: 0.0041 - val_loss: 0.0027\n",
            "Epoch 113/200\n",
            "42/42 - 0s - loss: 0.0042 - val_loss: 0.0020\n",
            "Epoch 114/200\n",
            "42/42 - 0s - loss: 0.0041 - val_loss: 0.0024\n",
            "Epoch 115/200\n",
            "42/42 - 0s - loss: 0.0041 - val_loss: 0.0029\n",
            "Epoch 116/200\n",
            "42/42 - 0s - loss: 0.0039 - val_loss: 0.0030\n",
            "Epoch 117/200\n",
            "42/42 - 0s - loss: 0.0043 - val_loss: 0.0018\n",
            "Epoch 118/200\n",
            "42/42 - 0s - loss: 0.0038 - val_loss: 0.0018\n",
            "Epoch 119/200\n",
            "42/42 - 0s - loss: 0.0038 - val_loss: 0.0019\n",
            "Epoch 120/200\n",
            "42/42 - 0s - loss: 0.0039 - val_loss: 0.0016\n",
            "Epoch 121/200\n",
            "42/42 - 0s - loss: 0.0043 - val_loss: 0.0022\n",
            "Epoch 122/200\n",
            "42/42 - 0s - loss: 0.0038 - val_loss: 0.0022\n",
            "Epoch 123/200\n",
            "42/42 - 0s - loss: 0.0038 - val_loss: 0.0022\n",
            "Epoch 124/200\n",
            "42/42 - 0s - loss: 0.0036 - val_loss: 0.0020\n",
            "Epoch 125/200\n",
            "42/42 - 0s - loss: 0.0036 - val_loss: 0.0020\n",
            "Epoch 126/200\n",
            "42/42 - 0s - loss: 0.0040 - val_loss: 0.0029\n",
            "Epoch 127/200\n",
            "42/42 - 0s - loss: 0.0039 - val_loss: 0.0017\n",
            "Epoch 128/200\n",
            "42/42 - 0s - loss: 0.0037 - val_loss: 0.0023\n",
            "Epoch 129/200\n",
            "42/42 - 0s - loss: 0.0041 - val_loss: 0.0019\n",
            "Epoch 130/200\n",
            "42/42 - 0s - loss: 0.0038 - val_loss: 0.0022\n",
            "Epoch 131/200\n",
            "42/42 - 0s - loss: 0.0039 - val_loss: 0.0027\n",
            "Epoch 132/200\n",
            "42/42 - 0s - loss: 0.0039 - val_loss: 0.0020\n",
            "Epoch 133/200\n",
            "42/42 - 0s - loss: 0.0039 - val_loss: 0.0028\n",
            "Epoch 134/200\n",
            "42/42 - 0s - loss: 0.0041 - val_loss: 0.0025\n",
            "Epoch 135/200\n",
            "42/42 - 0s - loss: 0.0036 - val_loss: 0.0015\n",
            "Epoch 136/200\n",
            "42/42 - 0s - loss: 0.0034 - val_loss: 0.0021\n",
            "Epoch 137/200\n",
            "42/42 - 0s - loss: 0.0038 - val_loss: 0.0020\n",
            "Epoch 138/200\n",
            "42/42 - 0s - loss: 0.0035 - val_loss: 0.0022\n",
            "Epoch 139/200\n",
            "42/42 - 0s - loss: 0.0036 - val_loss: 0.0021\n",
            "Epoch 140/200\n",
            "42/42 - 0s - loss: 0.0038 - val_loss: 0.0028\n",
            "Epoch 141/200\n",
            "42/42 - 0s - loss: 0.0037 - val_loss: 0.0021\n",
            "Epoch 142/200\n",
            "42/42 - 0s - loss: 0.0040 - val_loss: 0.0020\n",
            "Epoch 143/200\n",
            "42/42 - 0s - loss: 0.0036 - val_loss: 0.0018\n",
            "Epoch 144/200\n",
            "42/42 - 0s - loss: 0.0034 - val_loss: 0.0019\n",
            "Epoch 145/200\n",
            "42/42 - 0s - loss: 0.0038 - val_loss: 0.0027\n",
            "Epoch 146/200\n",
            "42/42 - 0s - loss: 0.0043 - val_loss: 0.0021\n",
            "Epoch 147/200\n",
            "42/42 - 0s - loss: 0.0036 - val_loss: 0.0022\n",
            "Epoch 148/200\n",
            "42/42 - 0s - loss: 0.0037 - val_loss: 0.0019\n",
            "Epoch 149/200\n",
            "42/42 - 0s - loss: 0.0035 - val_loss: 0.0019\n",
            "Epoch 150/200\n",
            "42/42 - 0s - loss: 0.0034 - val_loss: 0.0023\n",
            "Epoch 151/200\n",
            "42/42 - 0s - loss: 0.0039 - val_loss: 0.0019\n",
            "Epoch 152/200\n",
            "42/42 - 0s - loss: 0.0040 - val_loss: 0.0020\n",
            "Epoch 153/200\n",
            "42/42 - 0s - loss: 0.0037 - val_loss: 0.0020\n",
            "Epoch 154/200\n",
            "42/42 - 0s - loss: 0.0035 - val_loss: 0.0015\n",
            "Epoch 155/200\n",
            "42/42 - 0s - loss: 0.0038 - val_loss: 0.0016\n",
            "Epoch 156/200\n",
            "42/42 - 0s - loss: 0.0035 - val_loss: 0.0017\n",
            "Epoch 157/200\n",
            "42/42 - 0s - loss: 0.0035 - val_loss: 0.0014\n",
            "Epoch 158/200\n",
            "42/42 - 0s - loss: 0.0036 - val_loss: 0.0015\n",
            "Epoch 159/200\n",
            "42/42 - 0s - loss: 0.0032 - val_loss: 0.0018\n",
            "Epoch 160/200\n",
            "42/42 - 0s - loss: 0.0036 - val_loss: 0.0020\n",
            "Epoch 161/200\n",
            "42/42 - 0s - loss: 0.0033 - val_loss: 0.0016\n",
            "Epoch 162/200\n",
            "42/42 - 0s - loss: 0.0032 - val_loss: 0.0018\n",
            "Epoch 163/200\n",
            "42/42 - 0s - loss: 0.0033 - val_loss: 0.0016\n",
            "Epoch 164/200\n",
            "42/42 - 0s - loss: 0.0035 - val_loss: 0.0018\n",
            "Epoch 165/200\n",
            "42/42 - 0s - loss: 0.0033 - val_loss: 0.0014\n",
            "Epoch 166/200\n",
            "42/42 - 0s - loss: 0.0034 - val_loss: 0.0021\n",
            "Epoch 167/200\n",
            "42/42 - 0s - loss: 0.0033 - val_loss: 0.0015\n",
            "Epoch 168/200\n",
            "42/42 - 0s - loss: 0.0034 - val_loss: 0.0013\n",
            "Epoch 169/200\n",
            "42/42 - 0s - loss: 0.0035 - val_loss: 0.0020\n",
            "Epoch 170/200\n",
            "42/42 - 0s - loss: 0.0037 - val_loss: 0.0021\n",
            "Epoch 171/200\n",
            "42/42 - 0s - loss: 0.0033 - val_loss: 0.0024\n",
            "Epoch 172/200\n",
            "42/42 - 0s - loss: 0.0034 - val_loss: 0.0020\n",
            "Epoch 173/200\n",
            "42/42 - 0s - loss: 0.0033 - val_loss: 0.0013\n",
            "Epoch 174/200\n",
            "42/42 - 0s - loss: 0.0037 - val_loss: 0.0012\n",
            "Epoch 175/200\n",
            "42/42 - 0s - loss: 0.0031 - val_loss: 0.0013\n",
            "Epoch 176/200\n",
            "42/42 - 0s - loss: 0.0035 - val_loss: 0.0018\n",
            "Epoch 177/200\n",
            "42/42 - 0s - loss: 0.0031 - val_loss: 0.0013\n",
            "Epoch 178/200\n",
            "42/42 - 0s - loss: 0.0031 - val_loss: 0.0014\n",
            "Epoch 179/200\n",
            "42/42 - 0s - loss: 0.0033 - val_loss: 0.0014\n",
            "Epoch 180/200\n",
            "42/42 - 0s - loss: 0.0035 - val_loss: 0.0019\n",
            "Epoch 181/200\n",
            "42/42 - 0s - loss: 0.0033 - val_loss: 0.0016\n",
            "Epoch 182/200\n",
            "42/42 - 0s - loss: 0.0032 - val_loss: 0.0015\n",
            "Epoch 183/200\n",
            "42/42 - 0s - loss: 0.0033 - val_loss: 0.0015\n",
            "Epoch 184/200\n",
            "42/42 - 0s - loss: 0.0029 - val_loss: 0.0015\n",
            "Epoch 185/200\n",
            "42/42 - 0s - loss: 0.0030 - val_loss: 0.0016\n",
            "Epoch 186/200\n",
            "42/42 - 0s - loss: 0.0031 - val_loss: 9.5603e-04\n",
            "Epoch 187/200\n",
            "42/42 - 0s - loss: 0.0030 - val_loss: 0.0016\n",
            "Epoch 188/200\n",
            "42/42 - 0s - loss: 0.0032 - val_loss: 0.0023\n",
            "Epoch 189/200\n",
            "42/42 - 0s - loss: 0.0033 - val_loss: 0.0015\n",
            "Epoch 190/200\n",
            "42/42 - 0s - loss: 0.0031 - val_loss: 0.0013\n",
            "Epoch 191/200\n",
            "42/42 - 0s - loss: 0.0034 - val_loss: 0.0016\n",
            "Epoch 192/200\n",
            "42/42 - 0s - loss: 0.0032 - val_loss: 0.0012\n",
            "Epoch 193/200\n",
            "42/42 - 0s - loss: 0.0032 - val_loss: 0.0016\n",
            "Epoch 194/200\n",
            "42/42 - 0s - loss: 0.0031 - val_loss: 0.0011\n",
            "Epoch 195/200\n",
            "42/42 - 0s - loss: 0.0032 - val_loss: 0.0016\n",
            "Epoch 196/200\n",
            "42/42 - 0s - loss: 0.0029 - val_loss: 0.0018\n",
            "Epoch 197/200\n",
            "42/42 - 0s - loss: 0.0032 - val_loss: 0.0015\n",
            "Epoch 198/200\n",
            "42/42 - 0s - loss: 0.0032 - val_loss: 0.0018\n",
            "Epoch 199/200\n",
            "42/42 - 0s - loss: 0.0030 - val_loss: 0.0012\n",
            "Epoch 200/200\n",
            "42/42 - 0s - loss: 0.0028 - val_loss: 0.0010\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_vk1oZ7Lb4cl",
        "outputId": "11d4a9d7-e6dd-4e35-d634-de6b5cd1f4bc"
      },
      "source": [
        "# train autoencoder for classification with with compression in the bottleneck layer\r\n",
        "from sklearn.datasets import make_classification\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import Input\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.layers import LeakyReLU\r\n",
        "from tensorflow.keras.layers import BatchNormalization\r\n",
        "from tensorflow.keras.utils import plot_model\r\n",
        "from matplotlib import pyplot\r\n",
        "# define dataset\r\n",
        "X, y = make_classification(n_samples=10000, n_features=100, n_informative=10, n_redundant=90, random_state=1)\r\n",
        "# number of input columns\r\n",
        "n_inputs = X.shape[1]\r\n",
        "# split into train test sets\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\r\n",
        "# scale data\r\n",
        "t = MinMaxScaler()\r\n",
        "t.fit(X_train)\r\n",
        "X_train = t.transform(X_train)\r\n",
        "X_test = t.transform(X_test)\r\n",
        "# define encoder\r\n",
        "visible = Input(shape=(n_inputs,))\r\n",
        "# encoder level 1\r\n",
        "e = Dense(n_inputs*2)(visible)\r\n",
        "e = BatchNormalization()(e)\r\n",
        "e = LeakyReLU()(e)\r\n",
        "# encoder level 2\r\n",
        "e = Dense(n_inputs)(e)\r\n",
        "e = BatchNormalization()(e)\r\n",
        "e = LeakyReLU()(e)\r\n",
        "# bottleneck\r\n",
        "n_bottleneck = round(float(n_inputs) / 2.0)\r\n",
        "bottleneck = Dense(n_bottleneck)(e)\r\n",
        "# define decoder, level 1\r\n",
        "d = Dense(n_inputs)(bottleneck)\r\n",
        "d = BatchNormalization()(d)\r\n",
        "d = LeakyReLU()(d)\r\n",
        "# decoder level 2\r\n",
        "d = Dense(n_inputs*2)(d)\r\n",
        "d = BatchNormalization()(d)\r\n",
        "d = LeakyReLU()(d)\r\n",
        "# output layer\r\n",
        "output = Dense(n_inputs, activation='linear')(d)\r\n",
        "# define autoencoder model\r\n",
        "model = Model(inputs=visible, outputs=output)\r\n",
        "# compile autoencoder model\r\n",
        "model.compile(optimizer='adam', loss='mse')\r\n",
        "# plot the autoencoder\r\n",
        "plot_model(model, 'autoencoder_compress.png', show_shapes=True)\r\n",
        "# fit the autoencoder model to reconstruct input\r\n",
        "history = model.fit(X_train, X_train, epochs=200, batch_size=16, verbose=2, validation_data=(X_test,X_test))\r\n",
        "# plot loss\r\n",
        "pyplot.plot(history.history['loss'], label='train')\r\n",
        "pyplot.plot(history.history['val_loss'], label='test')\r\n",
        "pyplot.legend()\r\n",
        "pyplot.show()\r\n",
        "# define an encoder model (without the decoder)\r\n",
        "encoder = Model(inputs=visible, outputs=bottleneck)\r\n",
        "plot_model(encoder, 'encoder_compress.png', show_shapes=True)\r\n",
        "# save the encoder to file\r\n",
        "encoder.save('encoder.h5')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "419/419 - 4s - loss: 0.0385 - val_loss: 0.0056\n",
            "Epoch 2/200\n",
            "419/419 - 2s - loss: 0.0076 - val_loss: 0.0036\n",
            "Epoch 3/200\n",
            "419/419 - 2s - loss: 0.0057 - val_loss: 0.0024\n",
            "Epoch 4/200\n",
            "419/419 - 2s - loss: 0.0051 - val_loss: 0.0025\n",
            "Epoch 5/200\n",
            "419/419 - 2s - loss: 0.0046 - val_loss: 0.0025\n",
            "Epoch 6/200\n",
            "419/419 - 2s - loss: 0.0041 - val_loss: 0.0024\n",
            "Epoch 7/200\n",
            "419/419 - 2s - loss: 0.0039 - val_loss: 0.0020\n",
            "Epoch 8/200\n",
            "419/419 - 2s - loss: 0.0037 - val_loss: 0.0018\n",
            "Epoch 9/200\n",
            "419/419 - 2s - loss: 0.0037 - val_loss: 0.0016\n",
            "Epoch 10/200\n",
            "419/419 - 2s - loss: 0.0033 - val_loss: 0.0016\n",
            "Epoch 11/200\n",
            "419/419 - 2s - loss: 0.0033 - val_loss: 0.0013\n",
            "Epoch 12/200\n",
            "419/419 - 2s - loss: 0.0032 - val_loss: 0.0015\n",
            "Epoch 13/200\n",
            "419/419 - 2s - loss: 0.0031 - val_loss: 0.0011\n",
            "Epoch 14/200\n",
            "419/419 - 2s - loss: 0.0029 - val_loss: 0.0012\n",
            "Epoch 15/200\n",
            "419/419 - 2s - loss: 0.0028 - val_loss: 0.0011\n",
            "Epoch 16/200\n",
            "419/419 - 2s - loss: 0.0028 - val_loss: 0.0016\n",
            "Epoch 17/200\n",
            "419/419 - 2s - loss: 0.0027 - val_loss: 0.0014\n",
            "Epoch 18/200\n",
            "419/419 - 2s - loss: 0.0026 - val_loss: 0.0012\n",
            "Epoch 19/200\n",
            "419/419 - 2s - loss: 0.0025 - val_loss: 8.6081e-04\n",
            "Epoch 20/200\n",
            "419/419 - 2s - loss: 0.0024 - val_loss: 0.0011\n",
            "Epoch 21/200\n",
            "419/419 - 2s - loss: 0.0023 - val_loss: 0.0011\n",
            "Epoch 22/200\n",
            "419/419 - 2s - loss: 0.0022 - val_loss: 8.5134e-04\n",
            "Epoch 23/200\n",
            "419/419 - 2s - loss: 0.0022 - val_loss: 0.0010\n",
            "Epoch 24/200\n",
            "419/419 - 2s - loss: 0.0022 - val_loss: 8.7837e-04\n",
            "Epoch 25/200\n",
            "419/419 - 2s - loss: 0.0021 - val_loss: 8.7430e-04\n",
            "Epoch 26/200\n",
            "419/419 - 2s - loss: 0.0021 - val_loss: 6.4647e-04\n",
            "Epoch 27/200\n",
            "419/419 - 2s - loss: 0.0020 - val_loss: 5.5836e-04\n",
            "Epoch 28/200\n",
            "419/419 - 2s - loss: 0.0020 - val_loss: 7.2072e-04\n",
            "Epoch 29/200\n",
            "419/419 - 2s - loss: 0.0019 - val_loss: 5.7754e-04\n",
            "Epoch 30/200\n",
            "419/419 - 2s - loss: 0.0019 - val_loss: 5.2024e-04\n",
            "Epoch 31/200\n",
            "419/419 - 2s - loss: 0.0019 - val_loss: 7.3042e-04\n",
            "Epoch 32/200\n",
            "419/419 - 2s - loss: 0.0018 - val_loss: 5.4143e-04\n",
            "Epoch 33/200\n",
            "419/419 - 2s - loss: 0.0018 - val_loss: 4.9465e-04\n",
            "Epoch 34/200\n",
            "419/419 - 2s - loss: 0.0018 - val_loss: 5.7074e-04\n",
            "Epoch 35/200\n",
            "419/419 - 2s - loss: 0.0018 - val_loss: 5.2419e-04\n",
            "Epoch 36/200\n",
            "419/419 - 2s - loss: 0.0018 - val_loss: 7.8084e-04\n",
            "Epoch 37/200\n",
            "419/419 - 2s - loss: 0.0017 - val_loss: 6.6600e-04\n",
            "Epoch 38/200\n",
            "419/419 - 2s - loss: 0.0017 - val_loss: 5.5466e-04\n",
            "Epoch 39/200\n",
            "419/419 - 2s - loss: 0.0017 - val_loss: 4.0592e-04\n",
            "Epoch 40/200\n",
            "419/419 - 2s - loss: 0.0017 - val_loss: 5.8777e-04\n",
            "Epoch 41/200\n",
            "419/419 - 2s - loss: 0.0017 - val_loss: 6.7967e-04\n",
            "Epoch 42/200\n",
            "419/419 - 2s - loss: 0.0017 - val_loss: 5.5472e-04\n",
            "Epoch 43/200\n",
            "419/419 - 2s - loss: 0.0016 - val_loss: 5.9462e-04\n",
            "Epoch 44/200\n",
            "419/419 - 2s - loss: 0.0016 - val_loss: 4.7045e-04\n",
            "Epoch 45/200\n",
            "419/419 - 2s - loss: 0.0016 - val_loss: 6.8281e-04\n",
            "Epoch 46/200\n",
            "419/419 - 2s - loss: 0.0016 - val_loss: 4.0240e-04\n",
            "Epoch 47/200\n",
            "419/419 - 2s - loss: 0.0016 - val_loss: 4.8409e-04\n",
            "Epoch 48/200\n",
            "419/419 - 2s - loss: 0.0015 - val_loss: 3.4286e-04\n",
            "Epoch 49/200\n",
            "419/419 - 2s - loss: 0.0015 - val_loss: 4.7624e-04\n",
            "Epoch 50/200\n",
            "419/419 - 2s - loss: 0.0015 - val_loss: 6.3048e-04\n",
            "Epoch 51/200\n",
            "419/419 - 2s - loss: 0.0015 - val_loss: 3.9802e-04\n",
            "Epoch 52/200\n",
            "419/419 - 2s - loss: 0.0015 - val_loss: 5.0815e-04\n",
            "Epoch 53/200\n",
            "419/419 - 2s - loss: 0.0014 - val_loss: 4.6721e-04\n",
            "Epoch 54/200\n",
            "419/419 - 2s - loss: 0.0014 - val_loss: 3.9868e-04\n",
            "Epoch 55/200\n",
            "419/419 - 2s - loss: 0.0014 - val_loss: 3.9510e-04\n",
            "Epoch 56/200\n",
            "419/419 - 2s - loss: 0.0014 - val_loss: 3.1515e-04\n",
            "Epoch 57/200\n",
            "419/419 - 2s - loss: 0.0014 - val_loss: 4.6740e-04\n",
            "Epoch 58/200\n",
            "419/419 - 2s - loss: 0.0014 - val_loss: 3.5543e-04\n",
            "Epoch 59/200\n",
            "419/419 - 2s - loss: 0.0014 - val_loss: 4.2324e-04\n",
            "Epoch 60/200\n",
            "419/419 - 2s - loss: 0.0014 - val_loss: 4.9114e-04\n",
            "Epoch 61/200\n",
            "419/419 - 2s - loss: 0.0014 - val_loss: 3.8576e-04\n",
            "Epoch 62/200\n",
            "419/419 - 2s - loss: 0.0014 - val_loss: 2.7809e-04\n",
            "Epoch 63/200\n",
            "419/419 - 2s - loss: 0.0014 - val_loss: 4.5096e-04\n",
            "Epoch 64/200\n",
            "419/419 - 2s - loss: 0.0014 - val_loss: 4.7969e-04\n",
            "Epoch 65/200\n",
            "419/419 - 2s - loss: 0.0013 - val_loss: 3.5569e-04\n",
            "Epoch 66/200\n",
            "419/419 - 2s - loss: 0.0014 - val_loss: 4.2039e-04\n",
            "Epoch 67/200\n",
            "419/419 - 2s - loss: 0.0013 - val_loss: 3.3827e-04\n",
            "Epoch 68/200\n",
            "419/419 - 2s - loss: 0.0013 - val_loss: 2.9123e-04\n",
            "Epoch 69/200\n",
            "419/419 - 2s - loss: 0.0014 - val_loss: 4.2667e-04\n",
            "Epoch 70/200\n",
            "419/419 - 2s - loss: 0.0013 - val_loss: 4.7810e-04\n",
            "Epoch 71/200\n",
            "419/419 - 2s - loss: 0.0013 - val_loss: 3.1589e-04\n",
            "Epoch 72/200\n",
            "419/419 - 2s - loss: 0.0013 - val_loss: 4.0757e-04\n",
            "Epoch 73/200\n",
            "419/419 - 2s - loss: 0.0013 - val_loss: 3.4002e-04\n",
            "Epoch 74/200\n",
            "419/419 - 2s - loss: 0.0013 - val_loss: 3.5475e-04\n",
            "Epoch 75/200\n",
            "419/419 - 2s - loss: 0.0013 - val_loss: 3.6533e-04\n",
            "Epoch 76/200\n",
            "419/419 - 2s - loss: 0.0012 - val_loss: 2.6537e-04\n",
            "Epoch 77/200\n",
            "419/419 - 2s - loss: 0.0013 - val_loss: 2.7663e-04\n",
            "Epoch 78/200\n",
            "419/419 - 2s - loss: 0.0012 - val_loss: 3.9314e-04\n",
            "Epoch 79/200\n",
            "419/419 - 2s - loss: 0.0012 - val_loss: 3.1212e-04\n",
            "Epoch 80/200\n",
            "419/419 - 2s - loss: 0.0012 - val_loss: 2.8044e-04\n",
            "Epoch 81/200\n",
            "419/419 - 2s - loss: 0.0012 - val_loss: 2.2374e-04\n",
            "Epoch 82/200\n",
            "419/419 - 2s - loss: 0.0012 - val_loss: 1.8837e-04\n",
            "Epoch 83/200\n",
            "419/419 - 2s - loss: 0.0012 - val_loss: 2.2515e-04\n",
            "Epoch 84/200\n",
            "419/419 - 2s - loss: 0.0012 - val_loss: 3.1364e-04\n",
            "Epoch 85/200\n",
            "419/419 - 2s - loss: 0.0012 - val_loss: 3.3347e-04\n",
            "Epoch 86/200\n",
            "419/419 - 2s - loss: 0.0012 - val_loss: 2.8844e-04\n",
            "Epoch 87/200\n",
            "419/419 - 2s - loss: 0.0012 - val_loss: 4.4425e-04\n",
            "Epoch 88/200\n",
            "419/419 - 2s - loss: 0.0012 - val_loss: 2.9032e-04\n",
            "Epoch 89/200\n",
            "419/419 - 2s - loss: 0.0012 - val_loss: 2.7152e-04\n",
            "Epoch 90/200\n",
            "419/419 - 2s - loss: 0.0012 - val_loss: 2.6538e-04\n",
            "Epoch 91/200\n",
            "419/419 - 2s - loss: 0.0012 - val_loss: 3.3977e-04\n",
            "Epoch 92/200\n",
            "419/419 - 2s - loss: 0.0011 - val_loss: 3.1962e-04\n",
            "Epoch 93/200\n",
            "419/419 - 2s - loss: 0.0012 - val_loss: 2.5290e-04\n",
            "Epoch 94/200\n",
            "419/419 - 2s - loss: 0.0011 - val_loss: 2.8862e-04\n",
            "Epoch 95/200\n",
            "419/419 - 2s - loss: 0.0011 - val_loss: 2.1688e-04\n",
            "Epoch 96/200\n",
            "419/419 - 2s - loss: 0.0011 - val_loss: 2.4188e-04\n",
            "Epoch 97/200\n",
            "419/419 - 2s - loss: 0.0011 - val_loss: 3.0160e-04\n",
            "Epoch 98/200\n",
            "419/419 - 2s - loss: 0.0011 - val_loss: 2.7854e-04\n",
            "Epoch 99/200\n",
            "419/419 - 2s - loss: 0.0011 - val_loss: 2.5988e-04\n",
            "Epoch 100/200\n",
            "419/419 - 2s - loss: 0.0011 - val_loss: 2.2887e-04\n",
            "Epoch 101/200\n",
            "419/419 - 2s - loss: 0.0011 - val_loss: 3.0584e-04\n",
            "Epoch 102/200\n",
            "419/419 - 2s - loss: 0.0011 - val_loss: 2.1777e-04\n",
            "Epoch 103/200\n",
            "419/419 - 2s - loss: 0.0011 - val_loss: 2.9903e-04\n",
            "Epoch 104/200\n",
            "419/419 - 2s - loss: 0.0010 - val_loss: 3.0570e-04\n",
            "Epoch 105/200\n",
            "419/419 - 2s - loss: 0.0011 - val_loss: 2.3380e-04\n",
            "Epoch 106/200\n",
            "419/419 - 2s - loss: 0.0011 - val_loss: 2.6350e-04\n",
            "Epoch 107/200\n",
            "419/419 - 2s - loss: 0.0011 - val_loss: 2.3374e-04\n",
            "Epoch 108/200\n",
            "419/419 - 2s - loss: 0.0010 - val_loss: 2.1488e-04\n",
            "Epoch 109/200\n",
            "419/419 - 2s - loss: 0.0010 - val_loss: 1.9860e-04\n",
            "Epoch 110/200\n",
            "419/419 - 2s - loss: 0.0010 - val_loss: 1.8988e-04\n",
            "Epoch 111/200\n",
            "419/419 - 2s - loss: 0.0011 - val_loss: 3.1029e-04\n",
            "Epoch 112/200\n",
            "419/419 - 2s - loss: 0.0010 - val_loss: 2.9251e-04\n",
            "Epoch 113/200\n",
            "419/419 - 2s - loss: 0.0011 - val_loss: 2.1925e-04\n",
            "Epoch 114/200\n",
            "419/419 - 2s - loss: 0.0011 - val_loss: 2.3593e-04\n",
            "Epoch 115/200\n",
            "419/419 - 2s - loss: 0.0010 - val_loss: 2.8690e-04\n",
            "Epoch 116/200\n",
            "419/419 - 2s - loss: 0.0011 - val_loss: 3.5254e-04\n",
            "Epoch 117/200\n",
            "419/419 - 2s - loss: 0.0010 - val_loss: 2.0196e-04\n",
            "Epoch 118/200\n",
            "419/419 - 2s - loss: 0.0010 - val_loss: 2.2036e-04\n",
            "Epoch 119/200\n",
            "419/419 - 2s - loss: 0.0011 - val_loss: 3.0739e-04\n",
            "Epoch 120/200\n",
            "419/419 - 2s - loss: 0.0010 - val_loss: 2.7168e-04\n",
            "Epoch 121/200\n",
            "419/419 - 2s - loss: 0.0010 - val_loss: 2.1245e-04\n",
            "Epoch 122/200\n",
            "419/419 - 2s - loss: 0.0010 - val_loss: 2.3569e-04\n",
            "Epoch 123/200\n",
            "419/419 - 2s - loss: 9.8602e-04 - val_loss: 2.5189e-04\n",
            "Epoch 124/200\n",
            "419/419 - 2s - loss: 9.7934e-04 - val_loss: 2.8993e-04\n",
            "Epoch 125/200\n",
            "419/419 - 2s - loss: 9.9600e-04 - val_loss: 2.6127e-04\n",
            "Epoch 126/200\n",
            "419/419 - 2s - loss: 9.9186e-04 - val_loss: 2.3761e-04\n",
            "Epoch 127/200\n",
            "419/419 - 2s - loss: 9.6136e-04 - val_loss: 2.6863e-04\n",
            "Epoch 128/200\n",
            "419/419 - 2s - loss: 0.0010 - val_loss: 2.1567e-04\n",
            "Epoch 129/200\n",
            "419/419 - 2s - loss: 9.9157e-04 - val_loss: 2.5684e-04\n",
            "Epoch 130/200\n",
            "419/419 - 2s - loss: 9.5736e-04 - val_loss: 2.6211e-04\n",
            "Epoch 131/200\n",
            "419/419 - 2s - loss: 9.7574e-04 - val_loss: 2.8434e-04\n",
            "Epoch 132/200\n",
            "419/419 - 2s - loss: 0.0010 - val_loss: 2.3610e-04\n",
            "Epoch 133/200\n",
            "419/419 - 2s - loss: 9.6894e-04 - val_loss: 2.6787e-04\n",
            "Epoch 134/200\n",
            "419/419 - 2s - loss: 9.6833e-04 - val_loss: 2.5843e-04\n",
            "Epoch 135/200\n",
            "419/419 - 2s - loss: 9.6968e-04 - val_loss: 1.8093e-04\n",
            "Epoch 136/200\n",
            "419/419 - 2s - loss: 9.5145e-04 - val_loss: 1.8291e-04\n",
            "Epoch 137/200\n",
            "419/419 - 2s - loss: 9.4945e-04 - val_loss: 2.2059e-04\n",
            "Epoch 138/200\n",
            "419/419 - 2s - loss: 9.7846e-04 - val_loss: 2.7424e-04\n",
            "Epoch 139/200\n",
            "419/419 - 2s - loss: 0.0010 - val_loss: 1.3173e-04\n",
            "Epoch 140/200\n",
            "419/419 - 2s - loss: 9.4370e-04 - val_loss: 3.0709e-04\n",
            "Epoch 141/200\n",
            "419/419 - 2s - loss: 9.3593e-04 - val_loss: 2.0020e-04\n",
            "Epoch 142/200\n",
            "419/419 - 2s - loss: 9.1539e-04 - val_loss: 1.9198e-04\n",
            "Epoch 143/200\n",
            "419/419 - 2s - loss: 9.3649e-04 - val_loss: 1.8695e-04\n",
            "Epoch 144/200\n",
            "419/419 - 2s - loss: 9.6553e-04 - val_loss: 2.1088e-04\n",
            "Epoch 145/200\n",
            "419/419 - 2s - loss: 9.3836e-04 - val_loss: 2.4843e-04\n",
            "Epoch 146/200\n",
            "419/419 - 2s - loss: 9.3961e-04 - val_loss: 2.5416e-04\n",
            "Epoch 147/200\n",
            "419/419 - 2s - loss: 9.8057e-04 - val_loss: 2.3744e-04\n",
            "Epoch 148/200\n",
            "419/419 - 2s - loss: 9.2931e-04 - val_loss: 1.8212e-04\n",
            "Epoch 149/200\n",
            "419/419 - 2s - loss: 9.5539e-04 - val_loss: 2.7903e-04\n",
            "Epoch 150/200\n",
            "419/419 - 2s - loss: 9.3572e-04 - val_loss: 1.8374e-04\n",
            "Epoch 151/200\n",
            "419/419 - 2s - loss: 9.4684e-04 - val_loss: 2.8372e-04\n",
            "Epoch 152/200\n",
            "419/419 - 2s - loss: 9.7729e-04 - val_loss: 2.2994e-04\n",
            "Epoch 153/200\n",
            "419/419 - 2s - loss: 9.1221e-04 - val_loss: 2.5403e-04\n",
            "Epoch 154/200\n",
            "419/419 - 2s - loss: 9.4149e-04 - val_loss: 2.1294e-04\n",
            "Epoch 155/200\n",
            "419/419 - 2s - loss: 9.4328e-04 - val_loss: 2.6577e-04\n",
            "Epoch 156/200\n",
            "419/419 - 2s - loss: 9.2701e-04 - val_loss: 2.2837e-04\n",
            "Epoch 157/200\n",
            "419/419 - 2s - loss: 8.9371e-04 - val_loss: 1.7940e-04\n",
            "Epoch 158/200\n",
            "419/419 - 2s - loss: 9.3364e-04 - val_loss: 1.8295e-04\n",
            "Epoch 159/200\n",
            "419/419 - 2s - loss: 9.2936e-04 - val_loss: 2.3488e-04\n",
            "Epoch 160/200\n",
            "419/419 - 2s - loss: 9.0735e-04 - val_loss: 1.7791e-04\n",
            "Epoch 161/200\n",
            "419/419 - 2s - loss: 9.2415e-04 - val_loss: 1.3312e-04\n",
            "Epoch 162/200\n",
            "419/419 - 2s - loss: 9.5143e-04 - val_loss: 3.1936e-04\n",
            "Epoch 163/200\n",
            "419/419 - 2s - loss: 9.2679e-04 - val_loss: 2.4181e-04\n",
            "Epoch 164/200\n",
            "419/419 - 2s - loss: 8.8814e-04 - val_loss: 2.0866e-04\n",
            "Epoch 165/200\n",
            "419/419 - 2s - loss: 9.0444e-04 - val_loss: 3.5952e-04\n",
            "Epoch 166/200\n",
            "419/419 - 2s - loss: 9.0813e-04 - val_loss: 2.4369e-04\n",
            "Epoch 167/200\n",
            "419/419 - 2s - loss: 9.1460e-04 - val_loss: 2.6931e-04\n",
            "Epoch 168/200\n",
            "419/419 - 2s - loss: 9.6397e-04 - val_loss: 3.5057e-04\n",
            "Epoch 169/200\n",
            "419/419 - 2s - loss: 9.0772e-04 - val_loss: 1.9592e-04\n",
            "Epoch 170/200\n",
            "419/419 - 2s - loss: 8.5730e-04 - val_loss: 1.7582e-04\n",
            "Epoch 171/200\n",
            "419/419 - 2s - loss: 9.0520e-04 - val_loss: 2.4967e-04\n",
            "Epoch 172/200\n",
            "419/419 - 2s - loss: 8.8835e-04 - val_loss: 1.5367e-04\n",
            "Epoch 173/200\n",
            "419/419 - 2s - loss: 9.0578e-04 - val_loss: 2.1546e-04\n",
            "Epoch 174/200\n",
            "419/419 - 2s - loss: 8.9275e-04 - val_loss: 2.2373e-04\n",
            "Epoch 175/200\n",
            "419/419 - 2s - loss: 8.9145e-04 - val_loss: 2.7424e-04\n",
            "Epoch 176/200\n",
            "419/419 - 2s - loss: 8.9753e-04 - val_loss: 2.1925e-04\n",
            "Epoch 177/200\n",
            "419/419 - 2s - loss: 8.6293e-04 - val_loss: 2.9629e-04\n",
            "Epoch 178/200\n",
            "419/419 - 2s - loss: 9.1980e-04 - val_loss: 1.5378e-04\n",
            "Epoch 179/200\n",
            "419/419 - 2s - loss: 8.8432e-04 - val_loss: 2.0564e-04\n",
            "Epoch 180/200\n",
            "419/419 - 2s - loss: 8.8465e-04 - val_loss: 1.9867e-04\n",
            "Epoch 181/200\n",
            "419/419 - 2s - loss: 8.8483e-04 - val_loss: 1.6891e-04\n",
            "Epoch 182/200\n",
            "419/419 - 2s - loss: 8.9634e-04 - val_loss: 2.3996e-04\n",
            "Epoch 183/200\n",
            "419/419 - 2s - loss: 8.6985e-04 - val_loss: 1.6166e-04\n",
            "Epoch 184/200\n",
            "419/419 - 2s - loss: 8.7140e-04 - val_loss: 2.3953e-04\n",
            "Epoch 185/200\n",
            "419/419 - 2s - loss: 8.8368e-04 - val_loss: 2.2879e-04\n",
            "Epoch 186/200\n",
            "419/419 - 2s - loss: 8.8935e-04 - val_loss: 1.8933e-04\n",
            "Epoch 187/200\n",
            "419/419 - 2s - loss: 8.8094e-04 - val_loss: 1.7973e-04\n",
            "Epoch 188/200\n",
            "419/419 - 2s - loss: 8.9013e-04 - val_loss: 2.3523e-04\n",
            "Epoch 189/200\n",
            "419/419 - 2s - loss: 8.7293e-04 - val_loss: 1.6533e-04\n",
            "Epoch 190/200\n",
            "419/419 - 2s - loss: 8.6058e-04 - val_loss: 1.6526e-04\n",
            "Epoch 191/200\n",
            "419/419 - 2s - loss: 8.6610e-04 - val_loss: 2.0174e-04\n",
            "Epoch 192/200\n",
            "419/419 - 2s - loss: 8.6284e-04 - val_loss: 1.6298e-04\n",
            "Epoch 193/200\n",
            "419/419 - 2s - loss: 9.1526e-04 - val_loss: 2.0196e-04\n",
            "Epoch 194/200\n",
            "419/419 - 2s - loss: 8.3894e-04 - val_loss: 2.1130e-04\n",
            "Epoch 195/200\n",
            "419/419 - 2s - loss: 8.1866e-04 - val_loss: 2.0168e-04\n",
            "Epoch 196/200\n",
            "419/419 - 2s - loss: 8.9462e-04 - val_loss: 2.4726e-04\n",
            "Epoch 197/200\n",
            "419/419 - 2s - loss: 8.7569e-04 - val_loss: 1.9992e-04\n",
            "Epoch 198/200\n",
            "419/419 - 2s - loss: 8.2310e-04 - val_loss: 2.2784e-04\n",
            "Epoch 199/200\n",
            "419/419 - 2s - loss: 8.5812e-04 - val_loss: 2.9789e-04\n",
            "Epoch 200/200\n",
            "419/419 - 2s - loss: 8.7360e-04 - val_loss: 2.0606e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypue1NC4cT1V",
        "outputId": "56c410b9-0731-4219-cf2b-c60c3dbfad81"
      },
      "source": [
        "# baseline in performance with logistic regression model\r\n",
        "from sklearn.datasets import make_classification\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn import svm\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "# define dataset\r\n",
        "X, y = make_classification(n_samples=10000, n_features=100, n_informative=10, n_redundant=90, random_state=1)\r\n",
        "# split into train test sets\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\r\n",
        "# scale data\r\n",
        "t = MinMaxScaler()\r\n",
        "t.fit(X_train)\r\n",
        "X_train = t.transform(X_train)\r\n",
        "X_test = t.transform(X_test)\r\n",
        "# define model\r\n",
        "model = LogisticRegression()\r\n",
        "# fit model on training set\r\n",
        "model.fit(X_train, y_train)\r\n",
        "# make prediction on test set\r\n",
        "yhat = model.predict(X_test)\r\n",
        "# calculate accuracy\r\n",
        "acc = accuracy_score(y_test, yhat)\r\n",
        "print(acc)\r\n",
        "\r\n",
        "clf = svm.SVC()\r\n",
        "clf.fit(X_train, y_train)\r\n",
        "# calculate accuracy\r\n",
        "acc = accuracy_score(y_test, yhat)\r\n",
        "print(acc)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8378787878787879\n",
            "0.8378787878787879\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFk2Kf5NeLn-",
        "outputId": "a66a80b8-2542-4e67-9441-cb14d9958b8d"
      },
      "source": [
        "# evaluate logistic regression on encoded input\r\n",
        "from sklearn.datasets import make_classification\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn import svm\r\n",
        "from tensorflow.keras.models import load_model\r\n",
        "# define dataset\r\n",
        "X, y = make_classification(n_samples=1000, n_features=100, n_informative=10, n_redundant=90, random_state=1)\r\n",
        "# split into train test sets\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\r\n",
        "# scale data\r\n",
        "t = MinMaxScaler()\r\n",
        "t.fit(X_train)\r\n",
        "X_train = t.transform(X_train)\r\n",
        "X_test = t.transform(X_test)\r\n",
        "# load the model from file\r\n",
        "encoder = load_model('encoder.h5')\r\n",
        "# encode the train data\r\n",
        "X_train_encode = encoder.predict(X_train)\r\n",
        "# encode the test data\r\n",
        "X_test_encode = encoder.predict(X_test)\r\n",
        "# define the model\r\n",
        "model = LogisticRegression()\r\n",
        "# fit the model on the training set\r\n",
        "model.fit(X_train_encode, y_train)\r\n",
        "# make predictions on the test set\r\n",
        "yhat = model.predict(X_test_encode)\r\n",
        "# calculate classification accuracy\r\n",
        "acc = accuracy_score(y_test, yhat)\r\n",
        "print(acc)\r\n",
        "\r\n",
        "clf = svm.SVC()\r\n",
        "clf.fit(X_train, y_train)\r\n",
        "# calculate accuracy\r\n",
        "acc = accuracy_score(y_test, yhat)\r\n",
        "print(acc)\r\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "0.9363636363636364\n",
            "0.9363636363636364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}