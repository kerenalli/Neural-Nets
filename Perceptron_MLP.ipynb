{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptron_MLP.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN05qlx4WfyJF2Sh4g1ukbR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kerenalli/Neural-Nets/blob/main/Perceptron_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCcJB66XR4-P"
      },
      "source": [
        "TensorFlow is a software library extensively used in machine learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hyn5qF4nRv2s",
        "outputId": "84948de5-0c5d-4c1e-ae10-1470dfa3a277"
      },
      "source": [
        "%tensorflow_version 2.x\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "# Download and import the MIT 6.S191 package\r\n",
        "!pip install mitdeeplearning\r\n",
        "import mitdeeplearning as mdl\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mitdeeplearning\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/ad/650eb53c0d9d1213536fe94bc150f89b564ff5ee784bd662272584bb091b/mitdeeplearning-0.2.0.tar.gz (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mitdeeplearning) (1.19.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from mitdeeplearning) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from mitdeeplearning) (4.41.1)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from mitdeeplearning) (0.17.3)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->mitdeeplearning) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym->mitdeeplearning) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->mitdeeplearning) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->mitdeeplearning) (0.16.0)\n",
            "Building wheels for collected packages: mitdeeplearning\n",
            "  Building wheel for mitdeeplearning (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mitdeeplearning: filename=mitdeeplearning-0.2.0-cp37-none-any.whl size=2115442 sha256=d0b45fb38f53d27ac23c1cb3d70e4d7331c714fd9393606e1bc7fd4b4b0bb7df\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/dc/2a/5c3633135e7e4ef4fd31463cfa1942cb1bae7486ab94e7a2ad\n",
            "Successfully built mitdeeplearning\n",
            "Installing collected packages: mitdeeplearning\n",
            "Successfully installed mitdeeplearning-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQ_nQ79MSN_9"
      },
      "source": [
        "Tensors are data structures that you can think of as multi-dimensional arrays. Tensors are represented as n-dimensional arrays of base dataypes such as a string or integer -- they provide a way to generalize vectors and matrices to higher dimensions.\r\n",
        "\r\n",
        "The **shape** of a Tensor defines **its number of dimensions and the size of each dimension**. The **rank** of a Tensor provides the **number of dimensions** (n-dimensions) -- you can also think of this as the Tensor's order or degree."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjni6JBkSBtF",
        "outputId": "9f99438f-3379-42fe-ed40-5145ae83ae1b"
      },
      "source": [
        "sport = tf.constant(\"Tennis\", tf.string)\r\n",
        "number = tf.constant(1.41421356237, tf.float64)\r\n",
        "\r\n",
        "print(\"`sport` is a {}-d Tensor\".format(tf.rank(sport).numpy()))\r\n",
        "print(\"`number` is a {}-d Tensor\".format(tf.rank(number).numpy()))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`sport` is a 0-d Tensor\n",
            "`number` is a 0-d Tensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QB1DHcbS2IH"
      },
      "source": [
        "In the above output, 0-D tensor is just a number or **scalar**. **Vectors** and **lists** can be used to create 1-d Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZhOnDPES_ud",
        "outputId": "ee9d9b76-de98-41ef-f199-8722a2733d9c"
      },
      "source": [
        "sports = tf.constant([\"Tennis\", \"Basketball\"], tf.string)\r\n",
        "numbers = tf.constant([3.141592, 1.414213, 2.71821], tf.float64)\r\n",
        "\r\n",
        "print(\"`sports` is a {}-d Tensor with shape: {}\".format(tf.rank(sports).numpy(), tf.shape(sports)))\r\n",
        "print(\"`numbers` is a {}-d Tensor with shape: {}\".format(tf.rank(numbers).numpy(), tf.shape(numbers)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`sports` is a 1-d Tensor with shape: [2]\n",
            "`numbers` is a 1-d Tensor with shape: [3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3Fv-I16aViG",
        "outputId": "281e588f-bb51-4505-e64b-a2abb697c1be"
      },
      "source": [
        "sports = tf.constant([[\"Tennis\", \"Basketball\"],[\"Tennis\", \"Basketball\"]], tf.string)\r\n",
        "numbers = tf.constant([[3.141592, 1.414213],[3.141592, 2.71821]], tf.float64)\r\n",
        "\r\n",
        "print(\"`sports` is a {}-d Tensor with shape: {}\".format(tf.rank(sports).numpy(), tf.shape(sports)))\r\n",
        "print(\"`numbers` is a {}-d Tensor with shape: {}\".format(tf.rank(numbers).numpy(), tf.shape(numbers)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`sports` is a 2-d Tensor with shape: [2 2]\n",
            "`numbers` is a 2-d Tensor with shape: [2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exfEq5nda8la",
        "outputId": "fc31b6a4-7bfe-45a7-b053-c3eab5510a0f"
      },
      "source": [
        "### Defining higher-order Tensors ###\r\n",
        "'''TODO: Define a 2-d Tensor'''\r\n",
        "matrix =tf.constant([[\"Tennis\", \"Basketball\"],\r\n",
        "                     [\"Tennis\", \"Basketball\"]], tf.string) # TODO\r\n",
        "\r\n",
        "assert isinstance(matrix, tf.Tensor), \"matrix must be a tf Tensor object\"\r\n",
        "assert tf.rank(matrix).numpy() == 2\r\n",
        "print(matrix)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[b'Tennis' b'Basketball']\n",
            " [b'Tennis' b'Basketball']], shape=(2, 2), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8OV_pSJbxSR",
        "outputId": "6f91beb7-781c-4192-bfe7-925d311da64f"
      },
      "source": [
        "matrix1=tf.constant([[[1,2],[3,4]],[[1,2],[3,4]]])\r\n",
        "#here the matrix is 2x2x2\r\n",
        "row_vector = matrix1[1,1]\r\n",
        "column_vector = matrix1[0,0]\r\n",
        "scalar = matrix1[[1, 1,1]]\r\n",
        "#in this example we are printing the row vector of the matrix\r\n",
        "print(\"The matrix is:\")\r\n",
        "print(matrix1)\r\n",
        "print(\"`\\nrow_vector is`: {}\".format(row_vector.numpy()))\r\n",
        "print(\"\\n`column_vector is`: {}\".format(column_vector.numpy()))\r\n",
        "print(\"`\\nscalar`: {}\".format(scalar.numpy()))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The matrix is:\n",
            "tf.Tensor(\n",
            "[[[1 2]\n",
            "  [3 4]]\n",
            "\n",
            " [[1 2]\n",
            "  [3 4]]], shape=(2, 2, 2), dtype=int32)\n",
            "`\n",
            "row_vector is`: [3 4]\n",
            "\n",
            "`column_vector is`: [1 2]\n",
            "`\n",
            "scalar`: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVUpUMCLfKpX"
      },
      "source": [
        "# **1.2 Computations on Tensors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Z_qZi7afN1v"
      },
      "source": [
        "A convenient way to think about and visualize computations in TensorFlow is in terms of **graphs**. We can define this graph in terms of Tensors, which hold data, and the mathematical operations that act on these Tensors in **some order**. Let's look at a simple example, and define this computation using TensorFlow:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-w0mgUqcfHfo",
        "outputId": "41a687ed-4515-4bd7-e5be-cf1ef4335c42"
      },
      "source": [
        "# Create the nodes in the graph, and initialize values\r\n",
        "a = tf.constant(15)\r\n",
        "b = tf.constant(61)\r\n",
        "\r\n",
        "# Add them!\r\n",
        "c1 = tf.add(a,b)\r\n",
        "c2 = a + b # TensorFlow overrides the \"+\" operation so that it is able to act on Tensors\r\n",
        "print(a)\r\n",
        "print(\"\\n\")\r\n",
        "print(b)\r\n",
        "print(\"\\n\")\r\n",
        "print(c1)\r\n",
        "print(\"\\n\")\r\n",
        "print(c2)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(15, shape=(), dtype=int32)\n",
            "\n",
            "\n",
            "tf.Tensor(61, shape=(), dtype=int32)\n",
            "\n",
            "\n",
            "tf.Tensor(76, shape=(), dtype=int32)\n",
            "\n",
            "\n",
            "tf.Tensor(76, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3F6LPXTAgPVo",
        "outputId": "24c09254-0897-4dcc-d90f-3be7dd3ab72b"
      },
      "source": [
        "### Defining Tensor computations ###\r\n",
        "# Create the nodes in the graph, and initialize values\r\n",
        "#a = tf.constant(15)\r\n",
        "#b = tf.constant(61)\r\n",
        "# Construct a simple computation function\r\n",
        "def func(a,b):\r\n",
        "  '''TODO: Define the operation for c, d, e (use tf.add, tf.subtract, tf.multiply).'''\r\n",
        "  c = a+b# TODO\r\n",
        "  print(\"\\nValue of c is\")\r\n",
        "  print(c)\r\n",
        "  d =b-1 # TODO\r\n",
        "  print(\"\\nValue of d is\")\r\n",
        "  print(d)\r\n",
        "  e =c*d # TODO\r\n",
        "  return e\r\n",
        "\r\n",
        "\r\n",
        "# Consider example values for a,b\r\n",
        "a, b = 5,6\r\n",
        "# Execute the computation\r\n",
        "e_out = func(a,b)\r\n",
        "print(\"\\nFinal Value is\")\r\n",
        "print(e_out)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Value of c is\n",
            "11\n",
            "\n",
            "Value of d is\n",
            "5\n",
            "\n",
            "Final Value is\n",
            "55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMOr3jThhT5g"
      },
      "source": [
        "# **1.3 Neural networks in TensorFlow**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PoPOp-AhWAe"
      },
      "source": [
        "We can also define neural networks in TensorFlow. TensorFlow uses a high-level API called Keras that provides a powerful, intuitive framework for building and training deep learning models.\r\n",
        "\r\n",
        "Let's first consider the example of a simple perceptron defined by just one dense layer: $ y = \\sigma(Wx + b)$, where $W$ represents a matrix of weights, $b$ is a bias, $x$ is the input, $\\sigma$ is the sigmoid activation function, and $y$ is the output. We can also visualize this operation using a graph:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2aimnejhyEX",
        "outputId": "b1d2394d-3fec-418c-fd9d-8bd2ffc66bfe"
      },
      "source": [
        "### Defining a network Layer ###\r\n",
        "\r\n",
        "# n_output_nodes: number of output nodes\r\n",
        "# input_shape: shape of the input\r\n",
        "# x: input to the layer\r\n",
        "\r\n",
        "class OurDenseLayer(tf.keras.layers.Layer):\r\n",
        "  def __init__(self, n_output_nodes):\r\n",
        "    super(OurDenseLayer, self).__init__()\r\n",
        "    self.n_output_nodes = n_output_nodes\r\n",
        "\r\n",
        "  def build(self, input_shape):\r\n",
        "    d = int(input_shape[-1])\r\n",
        "    # Define and initialize parameters: a weight matrix W and bias b\r\n",
        "    # Note that parameter initialization is random!\r\n",
        "    self.W = self.add_weight(\"weight\", shape=[d, self.n_output_nodes]) # note the dimensionality\r\n",
        "    print(\"\\nThe weight matrix is: \\n\")\r\n",
        "    print(self.W)\r\n",
        "    self.b = self.add_weight(\"bias\", shape=[1, self.n_output_nodes]) # note the dimensionality\r\n",
        "    print(\"\\nThe Bias is: \\n\")\r\n",
        "    print(self.b)\r\n",
        "\r\n",
        "  def call(self, x):\r\n",
        "    '''TODO: define the operation for z (hint: use tf.matmul)'''\r\n",
        "    z = tf.matmul(x,self.W)+self.b # TODO\r\n",
        "    print(\"\\nThe calculated z is: \\n\")\r\n",
        "    print(z)\r\n",
        "\r\n",
        "    '''TODO: define the operation for out (hint: use tf.sigmoid)'''\r\n",
        "    y =tf.sigmoid(z) # TODO\r\n",
        "    print(\"\\nThe calculated y is: \\n\")\r\n",
        "    print(y)\r\n",
        "    return y\r\n",
        "\r\n",
        "# Since layer parameters are initialized randomly, we will set a random seed for reproducibility\r\n",
        "tf.random.set_seed(1)\r\n",
        "#here we have 1 output node\r\n",
        "layer = OurDenseLayer(3)\r\n",
        "layer.build((1,2))\r\n",
        "x_input = tf.constant([[1,2.]], shape=(1,2))\r\n",
        "y = layer.call(x_input)\r\n",
        "\r\n",
        "# test the output!\r\n",
        "print(y.numpy())\r\n",
        "mdl.lab1.test_custom_dense_layer_output(y)\r\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "The weight matrix is: \n",
            "\n",
            "<tf.Variable 'weight:0' shape=(2, 3) dtype=float32, numpy=\n",
            "array([[-0.73366153,  0.8796015 ,  0.28695   ],\n",
            "       [-0.14340228, -0.4558388 ,  0.3122064 ]], dtype=float32)>\n",
            "\n",
            "The Bias is: \n",
            "\n",
            "<tf.Variable 'bias:0' shape=(1, 3) dtype=float32, numpy=array([[ 0.02475715, -0.13831842, -0.2240473 ]], dtype=float32)>\n",
            "\n",
            "The calculated z is: \n",
            "\n",
            "tf.Tensor([[-0.99570894 -0.17039454  0.68731546]], shape=(1, 3), dtype=float32)\n",
            "\n",
            "The calculated y is: \n",
            "\n",
            "tf.Tensor([[0.26978594 0.45750415 0.66536945]], shape=(1, 3), dtype=float32)\n",
            "[[0.26978594 0.45750415 0.66536945]]\n",
            "[PASS] test_custom_dense_layer_output\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1j5LgdlWl2r9"
      },
      "source": [
        "Conveniently, TensorFlow has defined a number of Layers that are commonly used in neural networks, for example a Dense. Now, instead of using a single Layer to define our simple neural network, we'll use the Sequential model from Keras and a single Dense layer to define our network. With the Sequential API, you can readily create neural networks by stacking together layers like building blocks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUfF5cPamVzc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hd0chFimWTk"
      },
      "source": [
        "# **Keras Sequential Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHVI8-XXvVwI"
      },
      "source": [
        "# **1. Perceptron**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPg9dnufmexj"
      },
      "source": [
        "The Sequential model API is a way of creating deep learning models where an instance of the Sequential class is created and model layers are created and added to it. The layers can be defined and passed to the Sequential as an **array**.\r\n",
        "###from keras.models import Sequential\r\n",
        "###from keras.layers import Dense\r\n",
        "###model = Sequential([Dense(2, input_dim=1), Dense(1)])*.\r\n",
        "\r\n",
        "# **The Layers can also be added piecewise**\r\n",
        "###from keras.models import Sequential\r\n",
        "\r\n",
        "###from keras.layers import Dense\r\n",
        "\r\n",
        "###model = Sequential([Dense(2, input_dim=1), Dense(1)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1ogs6r1okyk"
      },
      "source": [
        "Models are defined by creating instances of layers and connecting them directly to each other in pairs, then defining a Model that specifies the layers to act as the input and output to the model.\r\n",
        "\r\n",
        "1.Defining Input\r\n",
        "2.Connecting Layers\r\n",
        "3.Creating the Model\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "XWP5Kxrvl33M",
        "outputId": "16b13a33-51fb-46a4-8b56-4c94ac2276d0"
      },
      "source": [
        "# Simple Perceptron\r\n",
        "from keras.utils import plot_model\r\n",
        "from keras.models import Model\r\n",
        "from keras.layers import Input\r\n",
        "from keras.layers import Dense\r\n",
        "#When input data is one-dimensional, such as for a multilayer Perceptron, \r\n",
        "#the shape must explicitly leave room for the shape of the mini-batch size used \r\n",
        "#when splitting the data when training the network. Therefore, \r\n",
        "#the shape tuple is always defined with a hanging last dimension when the input is one-dimensional (2,), for example:\r\n",
        "visible = Input(shape=(2,))\r\n",
        "\r\n",
        "'''The layers in the model are connected pairwise.\r\n",
        "This is done by specifying where the input comes from when defining each new layer.\r\n",
        "A bracket notation is used, such that after the layer is created, \r\n",
        "the layer from which the input to the current layer comes from is specified.'''\r\n",
        "\r\n",
        "hidden1 = Dense(2, activation='relu')(visible)\r\n",
        "output = Dense(1, activation='sigmoid')(hidden1)\r\n",
        "\r\n",
        "'''Keras provides a Model class that you can use to create a model from your \r\n",
        "created layers. It requires that you only specify the input and output layers. For example:'''\r\n",
        "\r\n",
        "model1 = Model(inputs=visible, outputs=output)\r\n",
        "\r\n",
        "# summarize layers\r\n",
        "print(model1.summary())\r\n",
        "\r\n",
        "# plot graph\r\n",
        "plot_model(model1, to_file='multilayer_perceptron_graph.png')\r\n",
        "\r\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 2)                 6         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 9\n",
            "Trainable params: 9\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zsWe_DVyDxv",
        "outputId": "82d2ee1d-f871-4b19-94c3-5cc808bd2924"
      },
      "source": [
        "# first neural network with keras tutorial\r\n",
        "from numpy import loadtxt\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "# load the dataset\r\n",
        "dataset = loadtxt('/content/pima-indians-diabetes.csv', delimiter=',')\r\n",
        "# split into input (X) and output (y) variables\r\n",
        "X = dataset[:,0:8]\r\n",
        "y = dataset[:,8]\r\n",
        "# define the keras model\r\n",
        "model = Sequential()\r\n",
        "model.add(Dense(8, input_dim=8, activation='relu'))\r\n",
        "model.add(Dense(8, activation='relu'))\r\n",
        "model.add(Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "print(model.summary())\r\n",
        "plot_model(model, to_file='perceptron_graph.png')\r\n",
        "\r\n",
        "# compile the keras model\r\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "\r\n",
        "# fit the keras model on the dataset\r\n",
        "model.fit(X, y, epochs=150, batch_size=10)\r\n",
        "# evaluate the keras model\r\n",
        "_, accuracy = model.evaluate(X, y)\r\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_15 (Dense)             (None, 8)                 72        \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 8)                 72        \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 153\n",
            "Trainable params: 153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "77/77 [==============================] - 1s 1ms/step - loss: 10.1038 - accuracy: 0.3301\n",
            "Epoch 2/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 2.5474 - accuracy: 0.3772\n",
            "Epoch 3/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 1.1246 - accuracy: 0.5562\n",
            "Epoch 4/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.8711 - accuracy: 0.5774\n",
            "Epoch 5/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.7817 - accuracy: 0.6240\n",
            "Epoch 6/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.7573 - accuracy: 0.6053\n",
            "Epoch 7/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6776 - accuracy: 0.6633\n",
            "Epoch 8/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6729 - accuracy: 0.6448\n",
            "Epoch 9/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6497 - accuracy: 0.6567\n",
            "Epoch 10/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6733 - accuracy: 0.6535\n",
            "Epoch 11/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6689 - accuracy: 0.6607\n",
            "Epoch 12/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6603 - accuracy: 0.6292\n",
            "Epoch 13/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6540 - accuracy: 0.6508\n",
            "Epoch 14/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6552 - accuracy: 0.6282\n",
            "Epoch 15/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.6128\n",
            "Epoch 16/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6278 - accuracy: 0.6595\n",
            "Epoch 17/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6266 - accuracy: 0.6723\n",
            "Epoch 18/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6382 - accuracy: 0.6574\n",
            "Epoch 19/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6642 - accuracy: 0.6105\n",
            "Epoch 20/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6458 - accuracy: 0.6367\n",
            "Epoch 21/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6395 - accuracy: 0.6552\n",
            "Epoch 22/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6253 - accuracy: 0.6655\n",
            "Epoch 23/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6306 - accuracy: 0.6535\n",
            "Epoch 24/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6278 - accuracy: 0.6455\n",
            "Epoch 25/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6550 - accuracy: 0.6211\n",
            "Epoch 26/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6324 - accuracy: 0.6574\n",
            "Epoch 27/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6158 - accuracy: 0.6606\n",
            "Epoch 28/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6290 - accuracy: 0.6464\n",
            "Epoch 29/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6279 - accuracy: 0.6409\n",
            "Epoch 30/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6098 - accuracy: 0.6668\n",
            "Epoch 31/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6238 - accuracy: 0.6526\n",
            "Epoch 32/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6168 - accuracy: 0.6601\n",
            "Epoch 33/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6157 - accuracy: 0.6675\n",
            "Epoch 34/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6338 - accuracy: 0.6464\n",
            "Epoch 35/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6249 - accuracy: 0.6564\n",
            "Epoch 36/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6123 - accuracy: 0.6676\n",
            "Epoch 37/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6060 - accuracy: 0.6699\n",
            "Epoch 38/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6231 - accuracy: 0.6668\n",
            "Epoch 39/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6185 - accuracy: 0.6605\n",
            "Epoch 40/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6099 - accuracy: 0.6666\n",
            "Epoch 41/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5967 - accuracy: 0.6962\n",
            "Epoch 42/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6045 - accuracy: 0.6605\n",
            "Epoch 43/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5938 - accuracy: 0.6813\n",
            "Epoch 44/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5932 - accuracy: 0.6906\n",
            "Epoch 45/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6164 - accuracy: 0.6779\n",
            "Epoch 46/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6031 - accuracy: 0.6565\n",
            "Epoch 47/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5985 - accuracy: 0.6623\n",
            "Epoch 48/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5848 - accuracy: 0.6939\n",
            "Epoch 49/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5986 - accuracy: 0.6721\n",
            "Epoch 50/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5780 - accuracy: 0.6953\n",
            "Epoch 51/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5885 - accuracy: 0.6887\n",
            "Epoch 52/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5932 - accuracy: 0.6988\n",
            "Epoch 53/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5733 - accuracy: 0.7160\n",
            "Epoch 54/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5737 - accuracy: 0.7125\n",
            "Epoch 55/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5773 - accuracy: 0.6940\n",
            "Epoch 56/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5603 - accuracy: 0.7220\n",
            "Epoch 57/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5489 - accuracy: 0.7327\n",
            "Epoch 58/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5655 - accuracy: 0.7153\n",
            "Epoch 59/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5755 - accuracy: 0.7092\n",
            "Epoch 60/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5806 - accuracy: 0.7104\n",
            "Epoch 61/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5906 - accuracy: 0.6899\n",
            "Epoch 62/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5507 - accuracy: 0.7163\n",
            "Epoch 63/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5335 - accuracy: 0.7524\n",
            "Epoch 64/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5638 - accuracy: 0.7293\n",
            "Epoch 65/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5624 - accuracy: 0.7095\n",
            "Epoch 66/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7429\n",
            "Epoch 67/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5743 - accuracy: 0.7081\n",
            "Epoch 68/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5525 - accuracy: 0.7240\n",
            "Epoch 69/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5490 - accuracy: 0.7376\n",
            "Epoch 70/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5466 - accuracy: 0.7460\n",
            "Epoch 71/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5509 - accuracy: 0.7259\n",
            "Epoch 72/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5525 - accuracy: 0.7099\n",
            "Epoch 73/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5288 - accuracy: 0.7416\n",
            "Epoch 74/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5317 - accuracy: 0.7507\n",
            "Epoch 75/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5481 - accuracy: 0.7305\n",
            "Epoch 76/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5129 - accuracy: 0.7702\n",
            "Epoch 77/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5152 - accuracy: 0.7520\n",
            "Epoch 78/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5330 - accuracy: 0.7418\n",
            "Epoch 79/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5260 - accuracy: 0.7480\n",
            "Epoch 80/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5313 - accuracy: 0.7505\n",
            "Epoch 81/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5146 - accuracy: 0.7660\n",
            "Epoch 82/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5038 - accuracy: 0.7637\n",
            "Epoch 83/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5259 - accuracy: 0.7346\n",
            "Epoch 84/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5026 - accuracy: 0.7624\n",
            "Epoch 85/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5284 - accuracy: 0.7546\n",
            "Epoch 86/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5150 - accuracy: 0.7602\n",
            "Epoch 87/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5201 - accuracy: 0.7599\n",
            "Epoch 88/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5434 - accuracy: 0.7278\n",
            "Epoch 89/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5300 - accuracy: 0.7393\n",
            "Epoch 90/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5104 - accuracy: 0.7494\n",
            "Epoch 91/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7464\n",
            "Epoch 92/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5129 - accuracy: 0.7692\n",
            "Epoch 93/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5488 - accuracy: 0.7276\n",
            "Epoch 94/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4866 - accuracy: 0.7794\n",
            "Epoch 95/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5145 - accuracy: 0.7689\n",
            "Epoch 96/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5258 - accuracy: 0.7386\n",
            "Epoch 97/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5185 - accuracy: 0.7548\n",
            "Epoch 98/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5240 - accuracy: 0.7432\n",
            "Epoch 99/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5269 - accuracy: 0.7477\n",
            "Epoch 100/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5367 - accuracy: 0.7365\n",
            "Epoch 101/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5236 - accuracy: 0.7459\n",
            "Epoch 102/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4966 - accuracy: 0.7642\n",
            "Epoch 103/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5165 - accuracy: 0.7486\n",
            "Epoch 104/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5089 - accuracy: 0.7593\n",
            "Epoch 105/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5053 - accuracy: 0.7482\n",
            "Epoch 106/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5123 - accuracy: 0.7284\n",
            "Epoch 107/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7964\n",
            "Epoch 108/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5041 - accuracy: 0.7492\n",
            "Epoch 109/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7563\n",
            "Epoch 110/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5080 - accuracy: 0.7626\n",
            "Epoch 111/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5158 - accuracy: 0.7245\n",
            "Epoch 112/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4858 - accuracy: 0.7886\n",
            "Epoch 113/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.7690\n",
            "Epoch 114/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.7532\n",
            "Epoch 115/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4954 - accuracy: 0.7706\n",
            "Epoch 116/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5130 - accuracy: 0.7624\n",
            "Epoch 117/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5081 - accuracy: 0.7576\n",
            "Epoch 118/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5015 - accuracy: 0.7599\n",
            "Epoch 119/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4898 - accuracy: 0.7782\n",
            "Epoch 120/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5186 - accuracy: 0.7503\n",
            "Epoch 121/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4911 - accuracy: 0.7802\n",
            "Epoch 122/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5031 - accuracy: 0.7511\n",
            "Epoch 123/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5081 - accuracy: 0.7539\n",
            "Epoch 124/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5259 - accuracy: 0.7342\n",
            "Epoch 125/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.7435\n",
            "Epoch 126/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5081 - accuracy: 0.7577\n",
            "Epoch 127/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4879 - accuracy: 0.7682\n",
            "Epoch 128/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7877\n",
            "Epoch 129/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5053 - accuracy: 0.7719\n",
            "Epoch 130/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.7496\n",
            "Epoch 131/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5026 - accuracy: 0.7684\n",
            "Epoch 132/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4691 - accuracy: 0.7795\n",
            "Epoch 133/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5187 - accuracy: 0.7403\n",
            "Epoch 134/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5250 - accuracy: 0.7385\n",
            "Epoch 135/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4931 - accuracy: 0.7684\n",
            "Epoch 136/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4829 - accuracy: 0.7746\n",
            "Epoch 137/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.7758\n",
            "Epoch 138/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4838 - accuracy: 0.7764\n",
            "Epoch 139/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4991 - accuracy: 0.7636\n",
            "Epoch 140/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4829 - accuracy: 0.7640\n",
            "Epoch 141/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7625\n",
            "Epoch 142/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5087 - accuracy: 0.7604\n",
            "Epoch 143/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4936 - accuracy: 0.7677\n",
            "Epoch 144/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5314 - accuracy: 0.7268\n",
            "Epoch 145/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4724 - accuracy: 0.7852\n",
            "Epoch 146/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7806\n",
            "Epoch 147/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4660 - accuracy: 0.7943\n",
            "Epoch 148/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4957 - accuracy: 0.7577\n",
            "Epoch 149/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.7637\n",
            "Epoch 150/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4899 - accuracy: 0.7817\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.4997 - accuracy: 0.7591\n",
            "Accuracy: 75.91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0WwenYTucXx"
      },
      "source": [
        "# ***2. Multi layer perceptron***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RoGRP1EQujU_",
        "outputId": "1ee876e1-e4e8-4588-ad28-f8fff5fd7d70"
      },
      "source": [
        "# Multilayer Perceptron\r\n",
        "from keras.utils import plot_model\r\n",
        "from keras.models import Model\r\n",
        "from keras.layers import Input\r\n",
        "from keras.layers import Dense\r\n",
        "#When input data is one-dimensional, such as for a multilayer Perceptron, \r\n",
        "#the shape must explicitly leave room for the shape of the mini-batch size used \r\n",
        "#when splitting the data when training the network. Therefore, \r\n",
        "#the shape tuple is always defined with a hanging last dimension when the input is one-dimensional (2,), for example:\r\n",
        "visible = Input(shape=(10,))\r\n",
        "\r\n",
        "'''The layers in the model are connected pairwise.\r\n",
        "This is done by specifying where the input comes from when defining each new layer.\r\n",
        "A bracket notation is used, such that after the layer is created, \r\n",
        "the layer from which the input to the current layer comes from is specified.'''\r\n",
        "\r\n",
        "hidden1 = Dense(10, activation='relu')(visible)\r\n",
        "hidden2 = Dense(20, activation='relu')(hidden1)\r\n",
        "hidden3 = Dense(30, activation='relu')(hidden2)\r\n",
        "hidden4 = Dense(20, activation='relu')(hidden3)\r\n",
        "hidden5 = Dense(10, activation='relu')(hidden4)\r\n",
        "output = Dense(1, activation='sigmoid')(hidden5)\r\n",
        "\r\n",
        "'''Keras provides a Model class that you can use to create a model from your \r\n",
        "created layers. It requires that you only specify the input and output layers. For example:'''\r\n",
        "\r\n",
        "model = Model(inputs=visible, outputs=output)\r\n",
        "\r\n",
        "# summarize layers\r\n",
        "print(model.summary())\r\n",
        "\r\n",
        "# plot graph\r\n",
        "plot_model(model, to_file='multilayer_perceptron_graph.png')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, 10)]              0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 30)                630       \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 20)                620       \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 10)                210       \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 1,801\n",
            "Trainable params: 1,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAALwAAAKECAIAAAAynccVAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nO3df1wTd54/8M/k9w8SfgkiTUCCPygCj9ZHyyHiSuuDVuqdVwVttKjo0tV6XdtaNbfGsn5ZqSJYemuhPlDbvauPYgBdVFawu6L0egd79hYVRaDg8cuIARqNIRFCmO8f404jBMxnJCTi+/mXM5+Zz3zyycuZzwyTGYIkSQQADparGwCePhAagA1CA7BBaAA2ju1EdXX1p59+6qqmALe1devWefPm0ZOP7Gk6OjpKSkomvEnArZWUlHR0dNjO4YxcqLi4eKLaA54CBEEMmwNjGoANQgOwQWgANggNwAahAdggNAAbhAZgg9AAbBAagA1CA7BBaAA2CA3ABqEB2CA0ABuT0Jw9e9bT0/PMmTPj3ponER8fT4zg4eHx2BVramqef/55FotFEMTUqVP37NkzAa2lnDhxQqFQUE0NCAhISUmZsE0/CTv30zzWU/Srl7i4uMcuExMTc+PGjcWLF587d66xsdHLy2sCGkZJSkpKSkqaMWNGT09PV1fXhG33CTHZ0yxZsuTevXv/9E//NO6tGcZsNsfGxjq4sEAgMBgMpI2NGzfu2LHDqS1kAOtDuSe3HtMcPXpUp9M5uHBFRYVEIqEnOzo6rl279uqrrzqnacxhfSj3hB2a77//PigoiCCIzz//HCGUn58vFotFItGpU6cSExOlUqlMJissLKQW/v3vfy8QCPz9/Tdt2jRt2jSBQBAbG/vXv/6VKt2yZQuPxwsICKAm/+Vf/kUsFhME0dPTgxD64IMPPvroo5aWFoIgZsyYgdvOffv2vf/++/RkRUWFVCrNzMx0ZF13+1D/+Z//GR4e7unpKRAIIiMjz507hxBKS0ujBkOhoaG1tbUIofXr14tEIk9Pz9OnTyOErFZrenp6UFCQUCiMiorSaDQIof3794tEIolEotPpPvroo+eee66xsdHBZvzMdn9O1Us+DnWb8cGDB6lJtVqNEDp//vy9e/d0Ot2CBQvEYvHAwAB9jBCLxfX19Q8ePLh+/frLL78skUja29up0rfffnvq1Kl0zdnZ2Qih7u5uajIpKSk0NPSx7Rmps7MzPDzcarXSc8rKyiQSSUZGxmirvP766wghvV4/8R8qNDTU09NzjI9TXFy8e/fun376qbe3NyYmxtfXl66KzWbfunWLXnL16tWnT5+m/r1t2zY+n19SUqLX63fu3MlisS5dukR/tPfff//gwYPLly+/cePGGJsmSRIhpNFobOeM2+EpNjZWKpX6+fkplcq+vr729na6iMPhPP/883w+Pzw8PD8///79+1999dV4bdeuffv2/frXv2axfv50S5YsMRgMH3/8MVY9bvKhkpOTf/vb33p7e/v4+CxdurS3t7e7uxsh9O6771qtVnq7BoPh0qVLb7zxBkLowYMH+fn5y5YtS0pK8vLy2rVrF5fLtW3hvn373nvvvRMnToSFheG2Z/zHNDweDyFksVjslr700ksikaihoWHct0vTarWnT59OTU0dxzpd/qFoXC4XIWS1WhFCr7766qxZs7788ktqf3D8+HGlUslmsxFCjY2NJpMpIiKCWksoFAYEBIxXC10wEObz+dR/FCfJysp65513BAKB8zYxklM/1J/+9Kf4+Hg/Pz8+n297PkgQxKZNm27evHn+/HmE0H/8x3/88pe/pIr6+voQQrt27aIvWbW1tZlMpnFpz0SHxmKx3L17VyaTOan+rq6ub775ZvPmzU6q3y5nfKjvvvsuNzcXIdTe3r5s2bKAgIC//vWv9+7dy8rKsl0sNTVVIBAcOXKksbFRKpUGBwdT8/38/BBCubm5tmOR6urqcWkbk4t7T+LixYskScbExDzcPIcz2j6fmaysrJSUFB8fn3Gs87Gc8aH+93//VywWI4Tq6uosFsvmzZsVCgUa8dM1b2/vt9566/jx4xKJ5J133qHny+VygUBw+fLlJ2yGXROxpxkaGtLr9YODg1evXv3ggw+CgoLoAceMGTN++umn0tJSi8XS3d3d1tZmu6KPj49Wq21tbb1//74jX8OdO3e+/PLLDz/8cGRReXm546fcjnDeh7JYLHfu3Ll48SIVmqCgIITQX/7ylwcPHvz444/0uT3t3Xff7e/vLysrs73cKhAI1q9fX1hYmJ+fbzAYrFZrZ2fn7du3x+fD2+6+HDnlPnjwIHURQiQSLV26NC8vTyQSIYRmzpzZ0tJSUFAglUoRQsHBwU1NTSRJbty4kcvlPvfccxwORyqVvvnmmy0tLXRtvb29r7zyikAgCAkJ+fWvf719+3aq06nT17/97W/BwcFCoTAuLq6rq2vshpEkuXXr1pSUFLtFZ8+elUgke/bsGVlUU1MzZ84c6lQrICAgMzNzwj7UF198ERoaOtpXc/LkSapClUrl4+Pj5eW1YsUK6vJYaGgofYZPkuSLL774m9/8Ztjn6u/vV6lUQUFBHA7Hz88vKSnp+vXrWVlZQqEQISSXy7/++uvHdilp75SbyXUaLBs3bvTx8RnfOl3O3T7UG2+8cfPmTSdVPjI0E3F4os4PJxmXfyj60Hb16lVqrzZhm3brvz3RGhoaRt72QFMqla5uoAuoVKoff/yxqalp/fr1v/vd7yZ027a7nXE/PP3mN7+hLotNnz69uLh4HGt2ITf5UGq1msViyeVy+u8GToJGHJ4I0ubmmKKiorfeeot8em6XAROAIAiNRrNy5Up6ztNxeAJuBUIDsEFoADYIDcAGoQHYIDQAG4QGYIPQAGwQGoANQgOwQWgANggNwAahAdjs3Fi+YsWKiW8HeIo8sqeRy+XJycmuaopb+eGHH3744QdXt8ItJCcny+Vy2zkE3D1jF3X7SFFRkasb4o5gTAOwQWgANggNwAahAdggNAAbhAZgg9AAbBAagA1CA7BBaAA2CA3ABqEB2CA0ABuEBmCD0ABsEBqADUIDsEFoADYIDcAGoQHYIDQAG4QGYIPQAGwQGoANQgOwQWgANggNwAahAdggNAAbhAZgg9AAbBAagA1CA7DBk7Ae+sMf/vDZZ5/RrzPt7u5GCPn5+VGTbDb7gw8+oN+8/YyD0DzU2NgYFhY2xgI3btwYe4FnBxyeHpo9e3ZkZCRBECOLCIKIjIyExNAgND9bu3Ytm80eOZ/D4axbt27i2+O24PD0M61WK5PJRnYIQRDt7e0ymcwlrXJDsKf5WWBgYGxsLIv1SJ+wWKzY2FhIjC0IzSPWrFkzbFhDEMTatWtd1R73BIenR/z0009Tp04dHByk57DZ7Dt37vj6+rqwVe4G9jSP8PHxSUhI4HAevjKCzWYnJCRAYoaB0AyXkpIyNDRE/ZskyTVr1ri2PW4IDk/D9fX1TZky5cGDBwghPp/f09Pj4eHh6ka5F9jTDCcWi5cuXcrlcjkczptvvgmJGQlCY8fbb789ODhotVpXr17t6ra4IzsvCXus6urqjo6OcW+K+7BarQKBgCRJo9E4ud/eI5fL582bh70aiQ9eJDZpJCcnMwgAkz0NtbHi4uLx/QBu5cKFCwRBxMfHu7ohTsT4vZMMQzPpLVy40NVNcF8QGvuG/QUK2IKuAdggNAAbhAZgg9AAbBAagA1CA7BBaAA2CA3ABqEB2CA0ABuEBmCD0ABsExSatLQ0iURCEMTly5cnZouPlZGRER4eLpVK+Xz+jBkzduzYYTQa6dI9e/YQj4qIiHCk2hMnTigUCtsVeTyev79/fHx8dna2Xq932geaOBMUmiNHjhw+fHhituWgysrK9957r7W1taen55NPPvnss88Y319iKykp6ebNm6GhoZ6eniRJDg0N6XS6oqKikJAQlUo1Z86cH3744cm34lrP7uHJw8Nj48aNPj4+Eolk5cqVy5Ytq6iosL2N9euvv7a9Xe3atWsMtkIQhJeXV3x8/FdffVVUVHTnzp0lS5bcu3dv/D6HC0xcaOw+xcOFysrKbJ8RMWXKFISQyWRy3haTk5NTU1N1Ot2hQ4ect5UJ4MTQkCSZnZ09e/ZsPp/v6em5fft221Kr1Zqenh4UFCQUCqOiojQaDUIoPz9fLBaLRKJTp04lJiZKpVKZTFZYWEivVVVVFR0dLRKJpFJpZGSkwWAYrSpct27dEgqFISEhjixcUVEhlUozMzNxt0I9S6u8vJyadLdOcBSzG8sduSFZrVYTBHHgwAG9Xm8ymfLy8hBCtbW1VOm2bdv4fH5JSYler9+5cyeLxbp06RK1FkLo/Pnz9+7d0+l0CxYsEIvFAwMDJEkajUapVJqVlWU2m7u6upYvX97d3T1GVY7r6+uTSCRbtmyh5/zud7+TyWReXl5cLnf69On//M///D//8z90aVlZmUQiycjIGK1CekwzDPUFy+Vyd+gEB7/HkZwVGpPJJBKJEhIS6DnU/xUqNGazWSQSKZVKemE+n79582by7/1lNpupIipqzc3N5N9HFWVlZbYbGqMqx6nV6lmzZhkMBnpOe3v73/72t/v37/f391dXV7/44otCofDatWsOVjhaaEiSpEY5Y7d8YjqBcWicdXhqbm42mUyLFi2yW9rY2GgymeiTWKFQGBAQ0NDQMHJJHo+HELJYLAghhULh7++fkpKye/fu1tZW3KpGc/LkyaKionPnzkkkEnqmXC5/8cUXPTw8eDxeTEzMV199ZTabqS/vSfT19ZEkKZVKsVo+AZ2AxVmh6ezsRDZPxxymr68PIbRr1y76YkZbW9tjB6FCobCysjIuLi4zM1OhUCiVSrPZzKwq2vHjx/ft23fx4sXp06ePsVhkZCSbzW5qanKw2tFQNVCP73OfTsDlrNAIBAKEUH9/v91SKky5ubm2O73q6urHVjtnzpwzZ85otVqVSqXRaHJychhXhRA6ePDgsWPHKisrAwMDx15yaGhoaGiIz+c7Uu0YKioqEEKJiYnIbTqBAWeFJiIigsViVVVV2S2Vy+UCgQD36rBWq62vr0cI+fn57d27d+7cufX19cyqIklSpVLV1dWVlpba/Yn/66+/bjtJDSqZ/ILVRldXV25urkwm27BhA3KDTmDMWaHx8/NLSkoqKSk5evSowWC4evVqQUEBXSoQCNavX19YWJifn28wGKxWa2dn5+3bt8euU6vVbtq0qaGhYWBgoLa2tq2tLSYmhllV9fX1+/fvP3z4MJfLtb3kn5OTQy1w69at48eP371712KxVFdXp6WlBQUFvfvuu1RpeXn5Y0+5SZI0Go1DQ0MkSXZ3d2s0mvnz57PZ7NLSUmpM4/JOYI7B4NnBUff9+/fT0tJ8fX09PDzi4uLS09MRQjKZ7MqVKyRJ9vf3q1SqoKAgDodDJez69et5eXkikQghNHPmzJaWloKCAqp/g4ODm5qaWltbY2Njvb292Wx2YGCgWq0eHBwcraqx21ZXV2e3N7Kzs6kFPvroo9DQULFYzOFwZDLZO++8o9Vq6dXPnj0rkUj27NkzsubTp09HRUWJRCIej0f94o46XYqOjs7IyOjt7bVd2LWdwPjsiclDjai/0Uzu33I/Cxh/j8/u354AY5MzNA0NDcTolEqlqxv4dJucDwAICwtjcNgFDpqcexrgVBAagA1CA7BBaAA2CA3ABqEB2CA0ABuEBmCD0ABsEBqADUIDsEFoADYIDcAGoQHYGN4a0dnZOblfhPQs6OzsZPi+cQa3iML7niaNibtH+FmwcuVKhBDsTe2CMQ3ABqEB2CA0ABuEBmCD0ABsEBqADUIDsEFoADYIDcAGoQHYIDQAG4QGYIPQAGwQGoANQgOwQWgANggNwAahAdggNAAbhAZgg9AAbBAagA1CA7BBaAA2CA3ABqEB2CA0ABuEBmCD0ABsEBqADUIDsEFoADYIDcA2OV9HyEBVVVVNTQ092dDQgBDKysqi58TExCxcuNAFLXM/8Pi0h/785z+/9tprXC6Xepm2raGhIYvF8u233yYkJLikbe4GQvOQ1WqdOnVqb2+v3VJvb2+dTsfhwI4ZIRjT0Nhs9ttvv83j8UYW8Xi8NWvWQGJoEJqfrVq1amBgYOT8gYGBVatWTXx73BYcnh4RHBzc3t4+bKZMJmtvbycIwiVNckOwp3lESkoKl8u1ncPj8datWweJsQV7mkfcuHEjPDx82My6urqIiAiXtMc9QWiGCw8Pv3HjBj0ZFhZmOwkQHJ5GWrt2LX2E4nK569atc2173BDsaYZrb2+fPn061S0EQdy8eXP69OmubpR7gT3NcEFBQS+99BKLxSII4uWXX4bEjAShsWPt2rUsFovNZq9Zs8bVbXFHcHiyo7u7e9q0aQihW7duTZ061dXNcT/wkrBnGbOXhDH8e0pMTMyHH344vh/ArVRVVREE8Ytf/MLVDXGi3NxcZisyDI1MJqPevTZZLV68GCEklUpd3RAnKi4uZrYi/OXWvskdlycEZ08AG4QGYIPQAGwQGoANQgOwQWgANggNwAahAdggNAAbhAZgg9AAbBAagA1CA7BNUGjS0tIkEglBEJcvX56YLT5WRkZGeHi4VCrl8/kzZszYsWOH0Wi0XcBisXzyySczZszg8XheXl4RERGtra2PrfbEiRMKhYKwwePx/P394+Pjs7Oz9Xq9sz7PRGJ25x6DO74KCwsRQrW1tQy26AwLFy7My8vr7e01GAwajYbL5S5evNh2gWXLls2ePbumpsZisWi12qVLl9bV1TlYeWhoqKenJ0mSQ0NDer3+woULqampBEFMmzbt0qVL4/9hGGH2PZIk+eyGZsmSJYODg/QkdU9Ze3s7NVlYWEgQxNWrV5lVTofGVnFxMYvF8vf3v3v3LrNqxxfj0EzcmMbdfg5dVlbGZrPpySlTpiCETCYTNfnFF1/MnTs3MjJyHLeYnJycmpqq0+kOHTo0jtVOPCeGhiTJ7Ozs2bNn8/l8T0/P7du325Zardb09PSgoCChUBgVFaXRaBBC+fn5YrFYJBKdOnUqMTFRKpXKZDJqF0WpqqqKjo4WiURSqTQyMtJgMIxWFa5bt24JhcKQkBCE0MDAQE1NzQsvvDDawhUVFVKpNDMzE3crqampCKHy8nJq0t06wVHO262p1WqCIA4cOKDX600mU15eHrI5PG3bto3P55eUlOj1+p07d7JYLOpgr1arEULnz5+/d++eTqdbsGCBWCweGBggSdJoNEql0qysLLPZ3NXVtXz58u7u7jGqclxfX59EItmyZQs1+X//938IoRdeeCE+Pj4gIIDP54eFhX3++edDQ0PUAmVlZRKJJCMjY7QK7R6eSJKkvmC5XO4OneB2YxqTySQSiRISEug5tmMas9ksEomUSiW9MJ/P37x5M/n3/jKbzVQRFbXm5maSJK9du4YQKisrs93QGFU5Tq1Wz5o1y2AwUJN1dXUIoYSEhP/6r//q7e29e/fuv/7rvyKEjh075mCFo4WGJEmCILy8vNyhE9xuTNPc3GwymRYtWmS3tLGx0WQy0c/vEAqFAQEB1AM1h6GeZ2axWBBCCoXC398/JSVl9+7d9Nmv41WN5uTJk0VFRefOnZNIJNQcPp+PEJozZ05sbKyPj4+np+f/+3//z9PTs6CgwPFq7err6yNJkrpr3a06AYuzQtPZ2YkQ8vPzs1va19eHENq1axd9MaOtrY0ehI5GKBRWVlbGxcVlZmYqFAqlUmk2m5lVRTt+/Pi+ffsuXrxo+5tt6ueVPT099BwejxccHNzS0uJgtaNpampCCIWFhSF36gRczgqNQCBACPX399stpcKUm5tru9Orrq5+bLVz5sw5c+aMVqtVqVQajSYnJ4dxVQihgwcPHjt2rLKyMjAw0Ha+h4fHzJkz6+vrbWcODg56eno6Uu0YKioqEEKJiYnIbTqBAWeFJiIigsViVVVV2S2Vy+UCgQD36rBWq6W+SD8/v717986dO7e+vp5ZVSRJqlSqurq60tJSDw+PkQu89dZbtbW1N2/epCZNJlNbW9sTnoF3dXXl5ubKZLINGzYgN+gExpwVGj8/v6SkpJKSkqNHjxoMhqtXr9oOCAQCwfr16wsLC/Pz8w0Gg9Vq7ezsvH379th1arXaTZs2NTQ0DAwM1NbWtrW1xcTEMKuqvr5+//79hw8f5nK5tpf8c3JyqAW2bt0aHBycmpra3t7e29urUqnMZjM1HEYIlZeXP/aUmyRJo9FInXB1d3drNJr58+ez2ezS0lJqTOPyTmCOweDZwVH3/fv309LSfH19PTw84uLi0tPTEUIymezKlSskSfb396tUqqCgIA6HQyXs+vXreXl5IpEIITRz5syWlpaCggKqf4ODg5uamlpbW2NjY729vdlsdmBgoFqtpi7p2q1q7LZR50cjZWdn08t0dHSsWrXK29ubz+dHR0eXl5fTRWfPnpVIJHv27BlZ8+nTp6OiokQiEY/Hox5+Tp0uRUdHZ2Rk9Pb22i7s2k5gfPbE5FEjK1asQE/wS2DgJhh/j3BrBMA2OUPT0NBAjE6pVLq6gU+3yfnUiLCwMAaHXeCgybmnAU4FoQHYIDQAG4QGYIPQAGwQGoANQgOwQWgANggNwAahAdggNAAbhAZgg9AAbBAagI3hrRElJSXu9ttswACzV3cxud2zurq6o6ODwcaeItS7kCb3O60QQnK5fN68ebhrwesI7aOePFJUVOTqhrgjGNMAbBAagA1CA7BBaAA2CA3ABqEB2CA0ABuEBmCD0ABsEBqADUIDsEFoADYIDcAGoQHYIDQAG4QGYIPQAGwQGoANQgOwQWgANggNwAahAdggNAAbhAZgg9AAbBAagA1CA7BBaAA2CA3ABqEB2CA0ABuEBmCbnG+WY6Cnp8dgMNCTfX19CCH6vdwIIalUOmXKFBe0zA0xeMPupHTkyJGxO+rIkSOubqO7gMenPaTX66dOnWqxWOyWcrncO3fueHt7T3Cr3BOMaR7y9vZevHgxh2PneM3hcBITEyExNAjNz1JSUqxW68j5Vqs1JSVl4tvjtuDw9LMHDx74+vqaTKZh84VCYU9Pj0gkckmr3BDsaX4mEAiWLVvG5XJtZ3K53KSkJEiMLQjNI1avXj1sLGyxWFavXu2q9rgnODw9YnBw0N/fX6/X03O8vLx0Ot2w3c8zDvY0j+BwOEqlksfjUZNcLnf16tWQmGEgNMOtWrVqYGCA+rfFYlm1apVr2+OG4PA0HEmSMplMq9UihAICArRaLbxvZhjY0wxHEERKSgqPx+NyuWvXroXEjAShsYM6QsF502iY/JX7008/ra6uHvemuBUPDw+E0J49e1zdEOeaN2/e1q1bcddiEprq6uqampqYmBgG6z4tgoODXd0Ep6upqWG2IsP7aWJiYoqLi5mt+1RoaWlBCIWGhrq6IU60YsUKZivCTVj2Te64PCEYCANsEBqADUIDsEFoADYIDcAGoQHYIDQAG4QGYIPQAGwQGoANQgOwQWgANggNwDZBoUlLS5NIJARBXL58eWK2+FgZGRnh4eFSqZTP58+YMWPHjh1Go5EujY+PJ0ag7swa24kTJxQKhe1aPB7P398/Pj4+Ozvb9scxT68JCs2RI0cOHz48MdtyUGVl5Xvvvdfa2trT0/PJJ5989tlnj72/JC4u7rHVJiUl3bx5MzQ01NPTkyTJoaEhnU5XVFQUEhKiUqnmzJnzww8/jNMncJln9/Dk4eGxceNGHx8fiUSycuXKZcuWVVRUdHR0UKUCgcBgMNg+lGXjxo07duzA3QpBEF5eXvHx8V999VVRUdGdO3eWLFly79698f40E2riQuNut/WXlZWx2Wx6knrKFf3r/4qKColEQpd2dHRcu3bt1VdffZItJicnp6am6nS6Q4cOPUk9LufE0JAkmZ2dPXv2bD6f7+npuX37dttSq9Wanp4eFBQkFAqjoqI0Gg1CKD8/XywWi0SiU6dOJSYmSqVSmUxWWFhIr1VVVRUdHS0SiaRSaWRkJPXAM7tV4bp165ZQKAwJCbFbum/fvvfff5+erKiokEqlmZmZuFtJTU1FCJWXl1OT7tYJjmLw9Kzk5OTk5OTHLqZWqwmCOHDggF6vN5lMeXl5CKHa2lqqdNu2bXw+v6SkRK/X79y5k8ViXbp0iVoLIXT+/Pl79+7pdLoFCxaIxeKBgQGSJI1Go1QqzcrKMpvNXV1dy5cv7+7uHqMqx/X19Ukkki1bttgt7ezsDA8Pt1qt9JyysjKJRJKRkTFahfSYZhjqC5bL5e7QCQ5+jyM5KzQmk0kkEiUkJNBzqP8rVGjMZrNIJFIqlfTCfD5/8+bN5N/7y2w2U0VU1Jqbm0mSvHbtGkKorKzMdkNjVOU4tVo9a9asYYMY2nvvvffFF19gVThaaEiSpEY5pBt0AuPQOOvw1NzcbDKZFi1aZLe0sbHRZDJFRERQk0KhMCAgoKGhYeSS1G/xqcd/KBQKf3//lJSU3bt3t7a24lY1mpMnTxYVFZ07d852EEPTarWnT5+mDitPrq+vjyRJqVSK3KwTsDgrNJ2dnQghPz8/u6XUA1d37dpFX8xoa2sb+QiqYYRCYWVlZVxcXGZmpkKhUCqVZrOZWVW048eP79u37+LFi9OnT7e7QFZW1jvvvCMQCByscGxNTU0IobCwMOROnYDLWaGherm/v99uKRWm3Nxc252eI7/anDNnzpkzZ7RarUql0mg0OTk5jKtCCB08ePDYsWOVlZWBgYF2F+jq6vrmm282b97sSG2OqKioQAglJiYit+kEBpwVmoiICBaLVVVVZbdULpcLBALcq8Narba+vh4h5Ofnt3fv3rlz59bX1zOriiRJlUpVV1dXWlo6xnXerKyslJQUHx8frMpH09XVlZubK5PJNmzYgNygExhzVmj8/PySkpJKSkqOHj1qMBiuXr1aUFBAlwoEgvXr1xcWFubn5xsMBqvV2tnZefv27bHr1Gq1mzZtamhoGBgYqK2tbWtri4mJYVZVfX39/v37Dx8+zOVybS/55+Tk0MvcuXPnyy+//PDDD0euXl5e/thTbpIkjUbj0NAQSZLd3VRLszUAABtISURBVN0ajWb+/PlsNru0tJQa07i8E5hjMHh2cNR9//79tLQ0X19fDw+PuLi49PR0hJBMJrty5QpJkv39/SqVKigoiMPhUAm7fv16Xl4e9UjEmTNntrS0FBQUUP0bHBzc1NTU2toaGxvr7e3NZrMDAwPVavXg4OBoVY3dtrq6Oru9kZ2dTS+zdevWlJQUu6ufPXtWIpHs2bNnZNHp06ejoqJEIhGPx2OxWOjvF4Wjo6MzMjJ6e3ttF3ZtJzA+e2LyUCPqbzST+7fczwLG3+Oz+7cnwNjkDE1DQ8PIGxtoSqXS1Q18uk3Op0aEhYUxOOwCB03OPQ1wKggNwAahAdggNAAbhAZgg9AAbBAagA1CA7BBaAA2CA3ABqEB2CA0ABuEBmCD0ABsDG+NqKmpYfwOD+AmGL9/iUlo5s2bx2Ctpwv1QJCXXnrJ1Q1xopiYGGZfJbz41L6VK1cihIqKilzdEHcEYxqADUIDsEFoADYIDcAGoQHYIDQAG4QGYIPQAGwQGoANQgOwQWgANggNwAahAdggNAAbhAZgg9AAbBAagA1CA7BBaAA2CA3ABqEB2CA0ABuEBmCD0ABsEBqADUIDsEFoADYIDcAGoQHYIDQAG4QGYIPQAGwQGoANnoT10B/+8IfPPvvMarVSk93d3QghPz8/apLNZn/wwQepqamuap5bgdA81NjYGBYWNsYCN27cGHuBZwccnh6aPXt2ZGQkQRAjiwiCiIyMhMTQIDQ/W7t2LZvNHjmfw+GsW7du4tvjtuDw9DOtViuTyUZ2CEEQ7e3tMpnMJa1yQ7Cn+VlgYGBsbCyL9UifsFis2NhYSIwtCM0j1qxZM2xYQxDE2rVrXdUe9wSHp0f89NNPU6dOHRwcpOew2ew7d+74+vq6sFXuBvY0j/Dx8UlISOBwHj79n81mJyQkQGKGgdAMl5KSMjQ0RP2bJMk1a9a4tj1uCA5Pw/X19U2ZMuXBgwcIIT6f39PT4+Hh4epGuRfY0wwnFouXLl3K5XI5HM6bb74JiRkJQmPH22+/PTg4aLVaV69e7eq2uCMm73uqrq7u6OgY96a4D6vVKhAISJI0Go2T++09crmcySufSHzJyclOaD9wgeTkZAYBYPg6wuTk5OLi4vH9AG7lwoULBEHEx8e7uiFOxPiFkgxDM+ktXLjQ1U1wXxAa+4b9BQrYgq4B2CA0ABuEBmCD0ABsEBqADUIDsEFoADYIDcAGoQHYIDQAG4QGYIPQAGwTFJq0tDSJREIQxOXLlydmi4+VkZERHh4ulUr5fP6MGTN27NhhNBptF/jmm29efvlliUQSHBy8fv36rq4uR6o9ceKEQqEgbPB4PH9///j4+OzsbL1e75xPM7GY3YTF4OadwsJChFBtbS2DLTrDwoUL8/Lyent7DQaDRqPhcrmLFy+mS48fP44QysrKunv3bm1trUKheOGFFywWi4OVh4aGenp6kiQ5NDSk1+svXLiQmppKEMS0adMuXbrklM+Dj9n3SJLksxuaJUuWDA4O0pMrV65ECLW3t1OTr7zySmBg4NDQEDX5+eefI4S+//57ByunQ2OruLiYxWL5+/vfvXv3iZs/DhiHZuLGNHaf4uFCZWVlts+ImDJlCkLIZDJRkx0dHdOmTaPbLJfLEUJtbW1PssXk5OTU1FSdTnfo0KEnqcflnBgakiSzs7Nnz57N5/M9PT23b99uW2q1WtPT04OCgoRCYVRUlEajQQjl5+eLxWKRSHTq1KnExESpVCqTyahdFKWqqio6OlokEkml0sjISIPBMFpVuG7duiUUCkNCQqhJhUKh0+noUmpAo1AoqMmKigqpVJqZmYm7FepZWuXl5e7ZCY5y3m5NrVYTBHHgwAG9Xm8ymfLy8pDN4Wnbtm18Pr+kpESv1+/cuZPFYlEHe7VajRA6f/78vXv3dDrdggULxGLxwMAASZJGo1EqlWZlZZnN5q6uruXLl3d3d49RleP6+vokEsmWLVvoORcvXuRyub///e8NBsO1a9eef/75119/nS4tKyuTSCQZGRmjVWj38ESSJPUFy+Vyd+gEtxvTmEwmkUiUkJBAz7Ed05jNZpFIpFQq6YX5fP7mzZvJv/eX2WymiqioNTc3kyR57do1hFBZWZnthsaoynFqtXrWrFkGg8F25q5du+j/WjKZrKOjw/EKRwsNSZIEQXh5eY3d8onpBLcb0zQ3N5tMpkWLFtktbWxsNJlMERER1KRQKAwICGhoaBi5JI/HQwhZLBaEkEKh8Pf3T0lJ2b17d2trK25Vozl58mRRUdG5c+ckEgk9U61WFxQUnD9/3mg03rx5MzY2dt68eU/+a6++vj6SJKVSKVbLJ6ATsDgrNJ2dncjm6ZjD9PX1IYR27dpFX8xoa2ujB6GjEQqFlZWVcXFxmZmZCoVCqVSazWZmVdGOHz++b9++ixcvTp8+nZ55+/btrKysX/3qV6+++qpYLA4JCTl8+LBWq83Oznaw2tE0NTUhhKjH97lPJ+ByVmgEAgFCqL+/324pFabc3FzbnV51dfVjq50zZ86ZM2e0Wq1KpdJoNDk5OYyrQggdPHjw2LFjlZWVgYGBtvN//PFHq9VqO1Mqlfr4+Fy/ft2RasdQUVGBEEpMTERu0wkMOCs0ERERLBarqqrKbqlcLhcIBLhXh7VabX19PULIz89v7969c+fOra+vZ1YVSZIqlaqurq60tHTkT/yph6Xdvn2bnnP//v2ffvqJOvFmrKurKzc3VyaTbdiwAblBJzDmrND4+fklJSWVlJQcPXrUYDBcvXq1oKCALhUIBOvXry8sLMzPzzcYDFartbOz0/ZLskur1W7atKmhoWFgYKC2tratrS0mJoZZVfX19fv37z98+DCXy7W95J+Tk4MQCgkJeeWVVw4fPvzdd9+ZzeaOjo6NGzcihH75y19Sq5eXlz/2lJskSaPRSF0e7O7u1mg08+fPZ7PZpaWl1JjG5Z3AHIPBs4Oj7vv376elpfn6+np4eMTFxaWnpyOEZDLZlStXSJLs7+9XqVRBQUEcDodK2PXr1/Py8kQiEUJo5syZLS0tBQUFVP8GBwc3NTW1trbGxsZ6e3uz2ezAwEC1Wk1d0rVb1dhtq6urs9sb2dnZ1AI9PT0ffPDBjBkz+Hy+h4fH/Pnz//jHP9Krnz17ViKR7NmzZ2TNp0+fjoqKEolEPB6P+sUddboUHR2dkZHR29tru7BrO4Hx2ROThxpRvwGe3L/lfhYw/h7h1giAbXKGpqGhgRidUql0dQOfbpPzAQBhYWEMDrvAQZNzTwOcCkIDsEFoADYIDcAGoQHYIDQAG4QGYIPQAGwQGoANQgOwQWgANggNwAahAdggNAAbw1sjOjs7J/eLkJ4FnZ2dDN83zuAWUXjf06QxcfcIPwuoJ4/A3tQuGNMAbBAagA1CA7BBaAA2CA3ABqEB2CA0ABuEBmCD0ABsEBqADUIDsEFoADYIDcAGoQHYIDQAG4QGYIPQAGwQGoANQgOwQWgANggNwAahAdggNAAbhAZgg9AAbBAagA1CA7BBaAA2CA3ABqEB2CA0ABuEBmCD0ABsk/N1hAxUVVXV1NTQkw0NDQihrKwsek5MTMzChQtd0DL3A49Pe+jPf/7za6+9xuVyqZdp2xoaGrJYLN9++21CQoJL2uZuIDQPWa3WqVOn9vb22i319vbW6XQcDuyYEYIxDY3NZr/99ts8Hm9kEY/HW7NmDSSGBqH52apVqwYGBkbOHxgYWLVq1cS3x23B4ekRwcHB7e3tw2bKZLL29naCIFzSJDcEe5pHpKSkcLlc2zk8Hm/dunWQGFuwp3nEjRs3wsPDh82sq6uLiIhwSXvcE4RmuPDw8Bs3btCTYWFhtpMAweFppLVr19JHKC6Xu27dOte2xw3Bnma49vb26dOnU91CEMTNmzenT5/u6ka5F9jTDBcUFPTSSy+xWCyCIF5++WVIzEgQGjvWrl3LYrHYbPaaNWtc3RZ3BIcnO7q7u6dNm4YQunXr1tSpU13dHPcDLwl7ljF7SRjDv6fExMR8+OGH4/sB3EpVVRVBEL/4xS9c3RAnys3NZbYiw9DIZDLq3WuT1eLFixFCUqnU1Q1xouLiYmYrwl9u7ZvccXlCcPYEsEFoADYIDcAGoQHYIDQAG4QGYIPQAGwQGoANQgOwQWgANggNwAahAdggNADbBIUmLS1NIpEQBHH58uWJ2eJjZWRkhIeHS6VSPp8/Y8aMHTt2GI1GutRisaSnpysUCh6P99xzz23bts1sNjtS7YkTJxQKBWGDx+P5+/vHx8dnZ2fr9XqnfaAJxOzOPQZ3fBUWFiKEamtrGWzRGRYuXJiXl9fb22swGDQaDZfLXbx4MV26efNmgUBQWFhoMBguXLgglUpXr17teOWhoaGenp4kSQ4NDen1+gsXLqSmphIEMW3atEuXLo3/h2GE2fdIkuSzG5olS5YMDg7Sk9Q9Ze3t7SRJtrS0sFisX/3qV3Tprl27EEL19fUOVk6HxlZxcTGLxfL397979+4TN38cMA7NxI1p3O3n0GVlZWw2m56cMmUKQshkMiGELl26NDQ09A//8A90KXUj37lz555ki8nJyampqTqd7tChQ09Sj8s5MTQkSWZnZ8+ePZvP53t6em7fvt221Gq1pqenBwUFCYXCqKgojUaDEMrPzxeLxSKR6NSpU4mJiVKpVCaTUbsoSlVVVXR0tEgkkkqlkZGRBoNhtKpw3bp1SygUhoSEIISoh2EJhUK6dObMmQgh+ve5FRUVUqk0MzMTdyupqakIofLycvfsBEc5b7emVqsJgjhw4IBerzeZTHl5ecjm8LRt2zY+n19SUqLX63fu3MlisaiDvVqtRgidP3/+3r17Op1uwYIFYrF4YGCAJEmj0SiVSrOyssxmc1dX1/Lly7u7u8eoynF9fX0SiWTLli3U5NWrVxFCH3/8Mb3A4OAgQmjZsmXUZFlZmUQiycjIGK1Cu4cnkiSpL1gul7tDJ7jdmMZkMolEooSEBHqO7ZjGbDaLRCKlUkkvzOfzN2/eTP69v8xmM1VERa25uZkkyWvXriGEysrKbDc0RlWOU6vVs2bNMhgM9JzFixf7+PicP3/ebDbfvn27qKiIIIh//Md/dLDC0UJDkiRBEF5eXmO3fGI6we3GNM3NzSaTadGiRXZLGxsbTSYT/fwOoVAYEBBAPVBzGOp5ZhaLBSGkUCj8/f1TUlJ2797d2tqKW9VoTp48WVRUdO7cOYlEQs88fvz4ihUr1q5d6+PjM3/+/D/+8Y8kSfr6+jperV19fX0kSVJ3rbtVJ2BxVmg6OzsRQn5+fnZL+/r6EEK7du2iL2a0tbVRg9AxCIXCysrKuLi4zMxMhUKhVCrNZjOzqmjHjx/ft2/fxYsXh/1m29PT89ChQ52dnSaTqaWl5cCBAwihwMBAB6sdTVNTE0IoLCwMuVMn4HJWaAQCAUKov7/fbikVptzcXNudXnV19WOrnTNnzpkzZ7RarUql0mg0OTk5jKtCCB08ePDYsWOVlZWPTcOlS5cQQq+88ooj1Y6hoqICIZSYmIjcphMYcFZoIiIiWCxWVVWV3VK5XC4QCHCvDmu12vr6eoSQn5/f3r17586dW19fz6wqkiRVKlVdXV1paamHh8djlz98+HBISMgTPny6q6srNzdXJpNt2LABuUEnMOas0Pj5+SUlJZWUlBw9etRgMFy9erWgoIAuFQgE69evLywszM/PNxgMVqu1s7Pz9u3bY9ep1Wo3bdrU0NAwMDBQW1vb1tYWExPDrKr6+vr9+/cfPnyYy+XaXvLPycmhFoiOjm5raxscHGxtbd22bdtf/vKXo0eP0g+MLS8vf+wpN0mSRqNxaGiIJMnu7m6NRjN//nw2m11aWkqNaVzeCcwxGDw7OOq+f/9+Wlqar6+vh4dHXFxceno6Qkgmk125coUkyf7+fpVKFRQUxOFwqIRdv349Ly9PJBIhhGbOnNnS0lJQUED1b3BwcFNTU2tra2xsrLe3N5vNDgwMVKvV1CVdu1WN3ba6ujq7vZGdnU0tkJCQ4OXlxeFwvL29lyxZMuz09ezZsxKJZM+ePSNrPn36dFRUlEgk4vF41PUe6nQpOjo6IyOjt7fXdmHXdgLjsycmjxpZsWIFeoJfAgM3wfh7hFsjALbJGZqGhgZidEql0tUNfLpNzqdGhIWFMTjsAgdNzj0NcCoIDcAGoQHYIDQAG4QGYIPQAGwQGoANQgOwQWgANggNwAahAdggNAAbhAZgg9AAbAxvjSgpKXG332YDBpi9uovJ7Z7V1dUdHR0MNvYUod6FNLnfaYUQksvl8+bNw10LXkdoH/XkkaKiIlc3xB3BmAZgg9AAbBAagA1CA7BBaAA2CA3ABqEB2CA0ABuEBmCD0ABsEBqADUIDsEFoADYIDcAGoQHYIDQAG4QGYIPQAGwQGoANQgOwQWgANggNwAahAdggNAAbhAZgg9AAbBAagA1CA7BBaAA2CA3ABqEB2CA0ANvkfLMcAz09PQaDgZ7s6+tDCN28eZOeI5VKp0yZ4oKWuSEGb9idlI4cOTJ2Rx05csTVbXQX8Pi0h/R6/dSpUy0Wi91SLpd7584db2/vCW6Ve4IxzUPe3t6LFy/mcOwcrzkcTmJiIiSGBqH5WUpKitVqHTnfarWmpKRMfHvcFhyefvbgwQNfX1+TyTRsvlAo7OnpEYlELmmVG4I9zc8EAsGyZcu4XK7tTC6Xm5SUBImxBaF5xOrVq4eNhS0Wy+rVq13VHvcEh6dHDA4O+vv76/V6eo6Xl5dOpxu2+3nGwZ7mERwOR6lU8ng8apLL5a5evRoSMwyEZrhVq1YNDAxQ/7ZYLKtWrXJte9wQHJ6GI0lSJpNptVqEUEBAgFarhffNDAN7muEIgkhJSeHxeFwud+3atZCYkSA0dlBHKDhvGg2Tv3J/+umn1dXV494Ut+Lh4YEQ2rNnj6sb4lzz5s3bunUr7lpMQlNdXV1TUxMTE8Ng3adFcHCwq5vgdDU1NcxWZHg/TUxMTHFxMbN1nwotLS0IodDQUFc3xIlWrFjBbEW4Ccu+yR2XJwQDYYANQgOwQWgANggNwAahAdggNAAbhAZgg9AAbBAagA1CA7BBaAA2CA3ABqEB2CYoNGlpaRKJhCCIy5cvT8wWHysrKyssLEwoFIrF4rCwsI8//tj2USMIoe+//37+/PkikWjatGkqlaq/v9+Rak+cOKFQKAgbPB7P398/Pj4+Ozvb9scxTzEGT5pITk5OTk7GXauwsBAhVFtby2CLzrBkyZKcnBydTnf//v2ioiIul5uQkECXXrt2TSgUfvzxx0aj8b//+7+nTJmyfv16xysPDQ319PQkSXJoaEiv11+4cCE1NZUgiGnTpl26dGn8PwwjzL5HkiSf3dAsW7bMbDbTk9QdSVqtlpp86623QkJChoaGqMns7GyCIG7cuOFg5XRobBUXF7NYLH9//7t37z5x88cB49BM3JjG3W7rP3nypEAgoCefe+45hJDRaEQIDQ4O/ulPf1q4cCHd5sTERJIkT5069SRbTE5OTk1N1el0hw4depJ6XM6JoSFJMjs7e/bs2Xw+39PTc/v27balVqs1PT09KChIKBRGRUVpNBqEUH5+vlgsFolEp06dSkxMlEqlMpmM2kVRqqqqoqOjRSKRVCqNjIykRiF2q8L1448/enl5UbcG37x502g0BgUF0aXUjXxXr16lJisqKqRSaWZmJu5WUlNTEULl5eXu2QmOct5uTa1WEwRx4MABvV5vMpny8vKQzeFp27ZtfD6/pKREr9fv3LmTxWJRB3u1Wo0QOn/+/L1793Q63YIFC8Ri8cDAAEmSRqNRKpVmZWWZzeaurq7ly5d3d3ePUZUjBgYGOjs7Dx48yOfzv/76a2pmVVUVQig7O9t2SaFQuGjRIurfZWVlEokkIyNjtGrtHp5IkqS+YLlc7g6d4HZjGpPJJBKJbIeWtmMas9ksEomUSiW9MJ/P37x5M/n3/qJHG1TUmpubSZK8du0aQqisrMx2Q2NU5YipU6cihHx9ff/t3/6N+lZIkvz2228RQp9++qntklKpNDY21sFqRwsNSZIEQXh5eY3d8onpBLcb0zQ3N5tMpkWLFtktbWxsNJlMERER1KRQKAwICGhoaBi5JPVbfOrxHwqFwt/fPyUlZffu3a2trbhV2dXR0aHT6b755pt///d/f/HFF3U6HUKIGusMDg7aLjkwMCAUCh2sdjR9fX0kSUqlUqyWO7sTcDkrNJ2dnQghPz8/u6XUA1d37dpFX8xoa2sb+QiqYYRCYWVlZVxcXGZmpkKhUCqVZrOZWVU0Lpfr5+f32muvHT9+/Pr165988glCKCAgACFke9nGZDI9ePBg2rRpDlY7mqamJoRQWFgYcqdOwOWs0FD/WUe7IEaFKTc313an58ivNufMmXPmzBmtVqtSqTQaTU5ODuOqhpkxYwabzb5+/TpCKCQkRCKRtLW10aXNzc0IoaioKNxqh6moqEAIJSYmIrfsBAc5KzQREREsFosaUY4kl8sFAgHu1WGtVltfX48Q8vPz27t379y5c+vr65lV1dvbO+x32j/++KPVapXL5QghDofzxhtvfPfdd0NDQ1RpeXk5QRBLly7F2sowXV1dubm5Mplsw4YNyA06gTFnhcbPzy8pKamkpOTo0aMGg+Hq1asFBQV0qUAgWL9+fWFhYX5+vsFgsFqtnZ2dt2/fHrtOrVa7adOmhoaGgYGB2tratra2mJgYZlWJxeJvv/22srLSYDBYLJba2tp169aJxWL6h80ff/zxnTt3fvvb3/b19VVXV2dnZ6emps6ePZsqLS8vf+wpN0mSRqORujzY3d2t0Wjmz5/PZrNLS0upMY3LO4E5BoNnB0fd9+/fT0tL8/X19fDwiIuLS09PRwjJZLIrV66QJNnf369SqYKCgjgcDpWw69ev5+XlUY9EnDlzZktLS0FBAdW/wcHBTU1Nra2tsbGx3t7ebDY7MDBQrVYPDg6OVtVjm7d06dKQkBAPDw8+nx8aGqpUKuvq6mwXoC6H8Pn8adOmbd++/cGDB3TR2bNnJRLJnj17RlZ7+vTpqKgokUjE4/FYLBZCiDpdio6OzsjI6O3ttV3YtZ3A+OyJyUONqCvuk/u33M8Cxt8j3BoBsE3O0DQ0NBCjUyqVrm7g021yPjUiLCyMwWEXOGhy7mmAU0FoADYIDcAGoQHYIDQAG4QGYIPQAGwQGoANQgOwQWgANggNwAahAdggNAAbhAZgY3hrRE1NDeN3eAA3wfj9S0xCM2/ePAZrAXcTExPD7KuEF58CbDCmAdggNAAbhAZgg9AAbP8fk71S5X/kdhsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41prPHfZvijf"
      },
      "source": [
        "# **3. Using the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "a98bUFryviO3",
        "outputId": "76177336-893d-481e-8e35-900acc79b10a"
      },
      "source": [
        "# first neural network with keras tutorial\r\n",
        "from numpy import loadtxt\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "# load the dataset\r\n",
        "dataset = loadtxt('/content/pima-indians-diabetes.csv', delimiter=',')\r\n",
        "# split into input (X) and output (y) variables\r\n",
        "X = dataset[:,0:8]\r\n",
        "y = dataset[:,8]\r\n",
        "# define the keras model\r\n",
        "model = Sequential()\r\n",
        "model.add(Dense(8, input_dim=8, activation='relu'))\r\n",
        "model.add(Dense(16, input_dim=8, activation='relu'))\r\n",
        "model.add(Dense(32, input_dim=8, activation='relu'))\r\n",
        "model.add(Dense(32, input_dim=8, activation='relu'))\r\n",
        "model.add(Dense(64, input_dim=8, activation='relu'))\r\n",
        "#model.add(Dense(128, input_dim=8, activation='relu'))\r\n",
        "#model.add(Dense(256, input_dim=8, activation='relu'))\r\n",
        "#model.add(Dense(512, input_dim=8, activation='relu'))\r\n",
        "#model.add(Dense(256, input_dim=8, activation='relu'))\r\n",
        "#model.add(Dense(128, input_dim=8, activation='relu'))\r\n",
        "#model.add(Dense(64, input_dim=8, activation='relu'))\r\n",
        "model.add(Dense(32, input_dim=8, activation='relu'))\r\n",
        "model.add(Dense(16, input_dim=8, activation='relu'))\r\n",
        "model.add(Dense(8, activation='relu'))\r\n",
        "model.add(Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "print(model.summary())\r\n",
        "plot_model(model, to_file='perceptron_graph.png')\r\n",
        "\r\n",
        "# compile the keras model\r\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "\r\n",
        "# fit the keras model on the dataset\r\n",
        "model.fit(X, y, epochs=150, batch_size=10)\r\n",
        "# evaluate the keras model\r\n",
        "_, accuracy = model.evaluate(X, y)\r\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-c34f567f0a3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# define the keras model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'leakyrelu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/activations.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    571\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0midentifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/activations.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(name, custom_objects)\u001b[0m\n\u001b[1;32m    534\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m       printable_module_name='activation function')\n\u001b[0m\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         raise ValueError(\n\u001b[0;32m--> 378\u001b[0;31m             'Unknown ' + printable_module_name + ': ' + object_name)\n\u001b[0m\u001b[1;32m    379\u001b[0m     \u001b[0;31m# Classes passed by name are instantiated with no args, functions are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# returned as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown activation function: leakyrelu"
          ]
        }
      ]
    }
  ]
}